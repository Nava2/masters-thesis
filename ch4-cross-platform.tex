\chapter{Developing cross-platform C++ applications}
\label{ch:cross-platform}

\newcommand{\cmakeinline}[1]{\mintinline{CMake}{#1}}
    
After concluding work on procsim.scala, we applied lessons learned from procsim.scala and applied them to the original hc12sim project. Unfortunately, the hc12sim simulator was dated, poorly designed and poorly organized due to inexperienced student work. A large effort was placed in modernizing and correcting the hc12sim software to be well tested, build in a cross-platform environment, reduce feature development time and reduce the amount of time required for maintenance. The hc12sim project was renamed procsim as it was intended to be a general purpose simulation framework rather than a single purpose \hcmodel{} simulator. In an effort to improve modernize procsim, we designed and set up continuous integration infrastructure to effectively develop a new procsim suite. This chapter discusses changes required to an aged code base to bring support the C++14 standard, upgrading existing CMake \cite{Kitware:CMake} build script infrastructure and developing multi-platform environments for automated platform testing.

\section{Modernizing hc12sim}
\label{sec:cross-platform:sec:modernizing}

The hc12sim project that was showcased in \cite{Brightwell2013} was modern at the time of development. Since 2013, the C++ community has progressed thoroughly and many of the libraries in use within the project were superseded by the Standard Template Library (STL) on most compiler platforms. The hc12sim project utilized many poor practices such as excessive use of \cxxinline{typedef} statements, over use of threads or abuse of operator overloading facilities. hc12sim heavily relied on Boost's non-standard implementations of \verb|tr1| structures such as \cxxinline{boost::shared_ptr<T>} \cite{Boost1.53.0:SmartPointers} (now superseded by C++11's STL \cxxinline{std::shared_ptr<T>} \cite{cppreference:shared-ptr}) and the \cxxinline{boost::thread} with it's associated tooling \cite{Boost1.53.0:Thread} (superseded by C++11's STL \cxxinline{<thread>} \cite{cppreference:thread}). The insidious nature of threading and smart pointer usage throughout the hc12sim software made this effort a large task. When writing C++ software, distribution of binary files is a common concern when working in cross-platform environments. Thus a concious effort was made to remove all large binary-based libraries in favour of simple-to-build or header-only libraries to remove concerns of finding pre-installed development packages on multiple platforms. After replacing existing Boost implementations with STL equivalents, these changes needed to be cross-platform tested to validate that the implementations by different compiler vendors on varied operating system configurations behaved as expected.


\section{Cross-platform development}
\label{sec:cross-platform:sec:cross-platform-development}

The C++ language has unofficially always tried to follow the motto: ``write once, compile anywhere.'' With any compiled language, when moving between platforms it is often non-trivial to assure compiled code runs between any two platforms. Given that \cref{req:personal} requires any solution must run on student's personal computers, we required procsim run on the three major platforms, Microsoft Windows, macOS and GNU/Linux. Within the C++ ecosystem, the ubiquitous way to maintain cross-platform support is to utilize only commonly used tools and depend on the Standard Template Library (STL) as much as possible. That is not to say there are not powerful cross platform libraries (e.g. Boost \cite{Boost}, Qt \cite{Qt}), these libraries provide excellent tools but often introduce complex build requirements and add large binary files into any distributed application. An artefact of 2013, Microsoft's Visual C++ (MSVC) 2011 compiler and accompanying STL were not completely standards compliant with C++11 and thus to use modern C++11 STL features hc12sim required the use of Boost to get non-standard but similar implementations \cite{Microsoft:MSVC:ModernCPP:2011}. Easing refactoring efforts was many of the C++11 STL additions were modelled after Boost's implementations \cite{Meyers2005}. For procsim Boost's STL implementation dependency were mostly removed by upgrading the lowest supported compiler to MSVC 2015. MSVC 2015 fully supports C++11 in both compiler semantics and STL compatibility \cite{Microsoft:MSVC:ModernCPP}. This allowed us to fully remove the main Boost dependencies on Boost.Memory and Boost.Thread by effectively renaming the \cxxinline{boost::} namespace to use \cxxinline{std::} namespace for the components in \cxxinline{<memory>} and \cxxinline{<thread>}. By removing these library dependencies, it eased cross-platform development as only the Boost C++ headers were required to compile procsim's core library. However, the unit test platform for hc12sim was based on Boost.Test \cite{Boost1.53.0:Test} -- a problem addressed later.

\subsection{Access to multiple platforms}

Once procsim utilized the C++11 STL over Boost, the next task was configuring mechanisms to ensure each platform performed correctly. It was found multiple times that different compiler's STL implementations behaved differently depending on different versions and the compilation target in use. For example, we found that the GNU Compiler Collection (GCC) \cite{GCC} 5.X C++ STL shipped with a broken version of the C++11 \cxxinline{<regex>} library \cite{StackOverflow:GCCRegex}. But the GCC front-end found on macOS had no such issues as it uses \texttt{libc++} provided by LLVM with a GCC compliant compiler command-line interface that runs Xcode's version of LLVM clang \cite{Apple:Developer:CommandLineTools}. This bug was found well after feature implementation due to testing on Xcode 8.3 and MSVC 2015 passing successfully (our two main platforms). Building on Linux was tested and the issue was found through unit tests checking a feature that utilized regex searching functionality. This small but frustrating issue opened up a question: How can the software be verified working on three major platforms while not having native access to each platform? The original approach was to change physical devices to access the different major operating systems. For each machine, we downloaded the software from the development repository and ran tests manually. It became difficult to maintain build environment changes made over time to successfully build the project as little records were maintained and compiling system projects heavily depend on environment variables. This meant sharing the software development environment became difficult and near impossible to replicate. Further, if a developer did not have access to Apple hardware, macOS software could not be tested. In previous works, we utilized VMWare vSphere \cite{VMWare:vSphere} technologies to create common developer environments through Virtual Machines that could be used for consistent development and testing. 

Given that vSphere is a proprietary and expensive software, we researched other tools that provided virtualized environments. Oracle's VirtualBox \cite{Oracle:VirtualBox} provides virtual machine provisioning through open source tools. Building on the idea of ``cloning'' common configurations between development environments through VirtualBox, we eventually found HashiCorp's Vagrant \cite{VagrantUp}. Vagrant provides a consistent declarative configuration for defining a virtual machine environments through Ruby scripts. Vagrant's parent company, HashiCorp, hosts ``boxes'' that are preconfigured virtual machines ranging from Ubuntu Linux to FreeBSD to macOS El Capitain \cite{Vagrant:Boxes}. Boxes provide a base VM image that users configure to match the environment requirements for a project. When a configuration is settled, developers commit the configuration file, known as a Vagrantfile, to their repository to live directly beside the software being developed. The intention of storing environment configuration within software repositories is to attempt to merge ``build'' teams and development teams as these are no longer distinct processes. For example, \cref{lst:cross-platform:ubuntu-vagrant-box} show cases a simple configuration that installs both GCC 5.X and LLVM Clang \cite{LLVM:Clang} 3.7 -- two fully C++11 compliant compiler tool-chains into a Ubuntu Trusty 14.04 box. Due to Vagrantfiles being Ruby programs, they have full access to Ruby's gem ecosystem. We used Vagrant and VirtualBox to create three environments for Microsoft Windows 10, macOS El Capitain, Ubuntu 14.04 Precise and Ubuntu 16.04 Xenial. These configurations allowed instantiating virtual machines quickly and consistently on any platform to build and run test configurations. Vagrant allows users to create their own boxes and we created a box for each base configuration for distribution that would save time for setting up a machine. Our Vagrant box configurations are available at \url{https://github.com/Nava2/procsim-bld} available under the MIT Open-source License. With the three major platforms easily accessible, it became necessary to improve the build infrastructure to be consistent across these platforms.

\begin{listing}[tp]
\begin{minted}[breaklines=true]{Ruby}
Vagrant.configure("2") do |config|
    # Utilize the ubuntu/trusty64 box to give a 14.04 environment
    config.vm.box = "ubuntu/trusty64"
    
    config.vm.provider "virtualbox" do |vb|
        vb.cpus = 2
        vb.memory = 2048
    end
    
    # Install/update prerequisite software:
    config.vm.provision "shell", privileged: true, inline: <<-EOF
        echo "Installing build prequisisites: git, compiler ppas"
        apt-get install -q -y git 
        # Compiler tool-chains
        apt-add-repository -y ppa:ubuntu-toolchain-r/test 
        apt-add-repository -y ppa:adrozdoff/llvm-backport 
        apt-get update -qq
    EOF
    
    config.vm.provision "shell", privileged: true, inline: <<-EOF
        echo "Installing build compiler toolchains"
        apt-get install -q -y clang-3.7 \
                              gcc-5 g++-5 \
                              --force-yes
    EOF
    
    # Update all existing packages last
    config.vm.provision "shell", privileged: true, inline: "apt-get dist-upgrade -y ; apt-get autoremove --purge -y"
end # end vagrant file 
\end{minted}
\caption{Vagrant file that describes a Ubuntu 14.04 box with modern GCC 5.X and LLVM Clang 3.7 compilers installed.}
\label{lst:cross-platform:ubuntu-vagrant-box}
\end{listing} 

\subsection{Building with cross-platform tools}

CMake \cite{Kitware:CMake} is a cross-platform meta-build system. A meta-build system provides a ``front-end'' language for defining a project's build and generates build scripts for other build systems to consume. CMake provides support for many different build systems, each is supported through a CMake ``generator.'' The generators we chose to build on the Windows, macOS and Linux were ``Unix Makefiles'' for GNU \texttt{make} \cite{GNU:Make} on Linux and macOS, ``Xcode'' for macOS's IDE Xcode \cite{Apple:Xcode}, and ``Visual Studio 14 2015 [Win64]'' for MSVC 2015 \cite{CMake:Generators}. On Unix environments, \texttt{make} is generally available however and a newer build tool, \texttt{ninja} \cite{NinjaBuild}, is preferred as builds are faster and provides the same familiar behaviours as \texttt{make}. As stated, CMake provides a cross-platform meta-build system, CMake can not abstract direct interactions with compilers due to tool-chain and operating system specific options. For example, turning on optimization flags on GCC/clang differs from the MSVC platform. The original hc12sim project utilized CMake, but it was poorly organized and added large build crippling file dependencies. Changing a single file likely caused the entire build to trigger as if running a clean build rather than running an incremental build. At first, this was thought to be caused by CMake not properly structuring inter-file dependencies, however it was soon found to be due to poor header isolation and deep nested coupling. We separated all headers to try and isolate concerns of what a header defines -- often breaking headers into multiple smaller single purpose headers. These efforts attempted to remove inter-dependencies as much as possible. Reorganization of the procsim library coupled with improved build tools and the addition of \texttt{OBJECT} library files \cite{CMake:add_library} significantly reduced build time and allowed for less time spent compiling procsim. 

As previously discussed, compilers come with consequential differences in support for new and current standards. In order to try and utilize features appropriately it is often helpful to ``test'' compilers support of features. CMake provides this functionality through cmake-compiler-features \cite{CMake:compile-features} but CMake's built-in support lags heavily behind current C++ standards (including C++14 and 17 at the time of writing). Fortunately, compatibility \cite{CMakeCompatibility} is a library used to enhance compiler and STL feature detection within CMake projects. We worked with M\"uller to improve compatibility features and generation of header files that will include a ``shim'' on top of the current STL to add features where possible. ``Shims'' can only be added for STL features as syntax elements are not extensible in C++. To counter a lack of syntax tokens in some compilers, compatibility scripts also automatically generated C-style macros for keywords that are only available in certain C++ tool-chains (e.g. \cxxinline{constexpr} or \cxxinline{override}). These macros were used to add extra meta-information for the compiler where available to improve code generation. The use of compatibility allowed procsim to build more easily on the heterogeneous compiler platforms required to work on most personal computers for \cref{req:personal} while simultaneously improving the software's performance where possible.

\section{Testing Infrastructure}

Testing a multi-platform compiled systems project is very difficult and relies on many tools to be successful. Through utilization of Vagrant and better build infrastructure within CMake scripts, procsim was able to be automatically tested on multiple platforms through continuous integration software. Continuous integration describes a process of building, testing and deploying software as rapidly as possible to reduce time-to-market for software projects \cite{Stolberg2009}. Idealistically, by utilizing continuous integration, developers receive near-instantaneous feedback on whether or not a particular change set breaks the product in unforeseen ways -- this heavily depends on the level of testing and environments available. For procsim, we configured a small ``micro-PC'' with an Intel \textregistered{} i5-4590T and 4 GB of RAM to run a Jenkins \cite{Jenkins:Home} continuous integration server running Jenkins. The device was chosen due having CPU accelerated virtualization to aid in running Oracle VirtualBox through Intel VT-X.  

Within Jenkins, Vagrant was used to create a new virtual machine for each test platform which registered as ``slaves'' to the ``master'' Jenkins service provided by Jenkins' distributed build infrastructure \cite{Jenkins:DistributedBuilds}. Each virtual machine spawned from a separate base box to test procsim's software test suites consistently. For example, one machine spawned a Ubuntu 14.04 machine with manually installed compiler tool-chains and a second machine spawned a macOS instance with Xcode 8. Each machine ran the exact same unit tests after configuration of the virtual machine and selection of a CMake generator. This was achieved through a Jenkins Pipeline \cite{Jenkins:Pipeline} specified in a Jenkinsfile script \cite{Jenkins:Pipeline:Jenkinsfile}. Jenkins Pipelines allow for parallel execution of ``tasks,'' dependent and independent, for a continuous integration task graph. For procsim, due to its immaturity, the pipeline only included stages for building the software and running unit tests within the multiple operating system platforms required by \cref{req:personal} -- deployment tasks were unused due to project maturity. While not strictly related to simulation \cref{req:simulations}, the addition of a continuous integration solution allowed us to maintain a rapid pace of development and provide confidence that changes made worked across all platforms without time consuming manual confirmation.

Over the course of developing procsim, the build process became more and more complicated requiring improvements in automating build script writing. When writing unit tests, the original hc12sim project utilized Boost.Test \cite{Boost1.53.0:Test} for creating and running unit tests. Unfortunately, Boost.Test required library distribution which made working on platforms without official software distribution systems difficult (e.g. Windows or macOS). In order to remove the final thread of Boost binary dependence, we replaced Boost.Test with Catch \cite{CatchLib}. Catch is a header-only C++ testing framework built on top of modern C++. Catch provides a Behaviour-Driven Development (BDD) interface that allows developers to describe the behaviour of their system within their tests creating easily understandable and clearly organized tests \cite{Solis2011}. Catch improved the mechanisms used to test and provided an easier to maintain testing suite. Catch's test runner requires that all tests are defined through C-style macros and the executable must include Catch's main once per test suite through the \cxxinline{CATCH_CONFIG_MAIN} macro \cite{CatchLib:Tutorial}. When defining many tests, it is often useful to organize them in meaningful ``suites'' of test executables. With any testing framework, when creating multiple executables it is advantageous to share object resources to reduce compiling time -- particularly in \cxxinline{template} or \cxxinline{constexpr} heavy software which procsim rapidly became.

\section{Improving developer work flows within CMake}
\label{sec:cross-platform:sec:cmake-flows}

In \cref{sec:cross-platform:sec:cross-platform-development}, CMake was discussed as the build tool for procsim. CMake utilizes \texttt{OBJECT} libraries to allow multiple ``targets'' to share compiled object files and statically link against the same objects as required \cite{CMake:add_library}. These \texttt{OBJECT} libraries are not the same as shared objects or DLLs and should not be treated as such. An \texttt{OBJECT} library is a CMake abstraction on top of compilation units that must be statically linked into some other object. These shared \texttt{OBJECT} libraries were very useful in unit test files as a common object used between each executable ``suite'' is the \texttt{main} test runner. They provide a faster compiling but unportable binary object similar to a static library. Manually specifying all of these suite instances to get individual suites and manually maintain a global ``test all'' suite created significant time investment and manual adjustments whenever files were added or removed from the project. We developed a series of CMake macros and functions to reduce the required commands to define tests and library files in a ``project-based'' work flow \cite{CMake:macro, CMake:function}. Within CMake, any action that has a side-effect or result is considered a \texttt{target}. When CMake executes a build script, it creates a graph of inter-\texttt{target} dependencies. From the \texttt{target} graph, CMake calculates a topological sort for a dependency resolution scheme used to build the project. \Cref{lst:lua:cmake-test-declaration} shows a simple shared library defined utilizing the build infrastructure described. Three functions are used to define four distinct targets: 
\begin{enumerate}
    \item \cmakeinline{new_project()} defines a ``project'' that logically groups libraries, executables and tests;
    \item A library, \texttt{procsim} with headers, sources and external dependencies;
    \item Two test ``groups'' of logically packaged tests for the library from (1) and adds a dependency on (1) and a common test harness;
    \item An aggregate \texttt{PROJECT} suite that combines all the tests from each group into a suite for the current project
\end{enumerate}
Within these functions, each performs many tasks to try and simplify definition of build components to form a completed program build. This could include setting common compiler flags, introduce dependencies on vendor libraries or generating build-time code required for the target. 

\begin{listing}[hp]
\begin{minted}{CMake}
new_project()

# Define a new library called ``procsim''
new_library(procsim 
    HEADERS procsim/encoding/Algorithm.hpp
            procsim/encoding/Code.hpp
            procsim/encoding/Operand.hpp
            procsim/encoding/Primitives.hpp
            procsim/encoding/Utility.hpp
            
            procsim/time/Clock.hpp
            procsim/time/Timer.hpp
            procsim/time/AsyncTimerReceiver.hpp
    
    SOURCES encoding/Algorithm.cpp
            encoding/Code.cpp
            encoding/Operand.cpp
            encoding/Primitives.cpp
    
            time/Clock.cpp
            time/Timer.cpp
            time/AsyncTimerReceiver.cpp
    
    GENERATED_HEADERS ${PROCSIM_EXPORT_HEADER}
                      ${PROCSIM_COMPILER_HEADER}
    VENDORS cpp17_libs fmtlib                      # non-builtin
    INCLUDE_DIRECTORIES ${Boost_INCLUDE_DIRS}
    LIBS                ${CMAKE_THREAD_LIBS_INIT}) # builtin libs

# Create two test suites utilizing the new library      
create_test(time     SOURCES time/ClockTest.cpp 
                             time/TimerTests.cpp
                     LIBS    procsim test-harness)
                     
create_test(encoding SOURCES encoding/CodeTest.cpp
                             encoding/OperandTest.cpp
                             encoding/PrimitivesTest.cpp
                             encoding/UtilityTest.cpp
                     LIBS    procsim test-harness)
# Create a test for the whole project
create_test(core     PROJECT)
\end{minted}
\caption{CMake script showing how two test suites, \cmakeinline{time} and \cmakeinline{encoding}, are defined as part of a project, \cmakeinline{core}}
\label{lst:cross-platform:cmake-test-declaration}
\end{listing}
 
The function, \cmakeinline{new_project()} defines a set of ``global'' variables within the build that are named after the directory that the current defined CMake script is found. For example, if \cref{lst:cross-platform:cmake-test-declaration} was found in ``procsim/core'' the project would be called ``core.'' This behaviour is meant to be consistent and simplistic between project definitions. This project model is based on the idea of ``convention over configuration'' which was popularized by tools and frameworks like Apache Maven and Ruby on Rails \cite{Maven:StandardDirectoryLayout,Heinemeier:RailsDoctrine}. For example, \cmakeinline{new_project()} defines the following configurable global variables: 
\begin{itemize}
    \item \texttt{SOURCE\_DIR}: Implementation files directory, defaulting to ``core/src''
    \item \texttt{INCLUDE\_DIR}: Header include directory, defaulting to ``core/include''
    \item \texttt{TEST\_DIR}: Test implementation directory, defaulting to ``core/test''
\end{itemize}
The \texttt{*\_DIR} properties allow for inner-project commands to use relative paths to simplify declaration of their file dependencies. These properties are used to generate ``namespaced'' build targets and variables allowing for use in specification within CMake's dependency graph. To simplify, if you define two projects, \verb|a| and \verb|b|, you can set \verb|b| to depend on \verb|a| being built first. In \cref{lst:cross-platform:cmake-test-declaration}, all of the files are specified relative to the ``project directory'' removing repeated values required in standard CMake scripts. Once the \cmakeinline{new_project()} function is called within a cmake script hierarchy, all further functions from the build tools will utilize the state set by the project. 

The function \cmakeinline{new_library()} creates a new library target that compiles all of the specified files to create a library. The function accepts \texttt{SHARED}, \texttt{STATIC}, \texttt{OBJECT}, etc. to mimic \cmakeinline{add_library()}'s syntax \cite{CMake:add_library}  -- an attempt to remove some discontinuity between the two functions. As shown in \cref{lst:cross-platform:cmake-test-declaration}, there are several other parameters used: 
\begin{itemize}
    \item \texttt{HEADERS} Header files
    \item \texttt{SOURCES} Implementation files
    \item \texttt{GENERATED\_SOURCES} Source files that are generated at build time by another target
    \item \texttt{GENERATED\_HEADERS} Same as \texttt{GENERATED\_SOURCES} except for header files
    \item \texttt{VENDORS} These are external dependencies that are built within the build chain after downloading from an external source. This forces the library to depend on their download and build
    \item \texttt{LIBS} These are internal CMake libraries or other targets that are built in a multi-project configuration
\end{itemize}
Utilizing these parameters, the function creates an appropriate CMake \texttt{target} using \\* \cmakeinline{add_library()} and adds the required dependencies to the new library target. In addition, it performs platform-specific compiler adjustments to try and reduce the amount of configurations required per target. For example, many flags for MSVC to not apply to Clang which do not apply to GCC. This torrent of compiler-specific option configuration is eased by the use of CMake's generator expressions \cite{CMake:generator-expressions} but many compilers do not properly identify to CMake's internal infrastructure so manual adjustments must be made for newer tool-chains. By utilizing our own mechanism, the \texttt{target}s created have ``localised'' properties such as include directories and \cmakeinline{target_properties()} added in reproducible ways that do not accidentally pollute other targets or the global variable space. For example, if two targets require different versions of the same files, the built-in \cmakeinline{include_directories()} command could cause these targets to ``collide'' and fail to compile \cite{CMake:include-directories}. \cmakeinline{new_library()} appropriately applies the \texttt{SYSTEM} option to all includes that are outside of the multi-project build so any warnings generated are not applied. Lastly, \texttt{install} targets are created that install headers and compiled binaries to appropriate locations depending on the type of library and the platform in use. For example, on Microsoft Windows requires libraries be beside their executables, where UNIX utilizes PATH resolution mechanics.

The last function used in \cref{lst:cross-platform:cmake-test-declaration} is \cmakeinline{create_test()} which has three distinct incantations. The first creates a single test suite from Catch-based test sources \cite{CatchLib}. These sources are aggregated and compiled to an \texttt{OBJECT} library \cite{CMake:add_library}. The test objects are aggregated for future linking into the current \texttt{PROJECT}'s test executable. By generating \texttt{OBJECT} libraries, these smaller units of compilation can be combined and reused intelligently saving large amounts of compile time as previously discussed. The second pattern as \cmakeinline{create_test(test PROJECT)} generates a \texttt{PROJECT}-based test executable and ``check'' target that runs the \texttt{PROJECT} test executable. This test executable includes all previously defined \texttt{OBJECT} libraries in the current ``project.'' This executable is used to debug and execute tests for the given project, it is currently not possible to run a smaller test individually without utilizing the selected test runner's (Catch) command-line interface manually. Additionally, the generated executable is registered with CMake's CTest which creates build-script targets to run test executables providing dashboards and other useful tools \cite{CMake:CTest}. 

The last use case is \cmakeinline{create_test(target ALL)}, not included in \cref{lst:cross-platform:cmake-test-declaration}. The \texttt{ALL} request generates a test executable that includes every test suite created in a multi-project build into a single executable -- a convenience executable. As multi-project programs develop, it is useful to be more or less granular with the scope of tests executed depending on the context required at the time of use. While intuitively it appears as though large amounts of executables create large amounts of compilation units creating a very slow build time, due to the use of \texttt{OBJECT} libraries created at definition, adding more test executables only adds incremental link time due to linking static objects -- a marginal increase of time for the convenience provided. Summarized test output from procsim's generated \texttt{ctest} command is shown in \cref{lst:cross-platform:ctest-output}. The output is easy to read and, should errors occur, Catch provides assertion errors and suites will continue summarizing all errors after a suite completes.

\begin{listing}[hb!]
\begin{verbatim}
1>--- Build started: Project: RUN_TESTS, Configuration: Debug x64 ---
1>  Test project S:/research/procsim/build-windows
1>        Start  1: core-components
1>   1/11 Test  #1: core-components ............   Passed    0.09 sec
1>        Start  2: core-encoding
1>   2/11 Test  #2: core-encoding ..............   Passed    0.06 sec
1>        Start  3: core-time
1>   3/11 Test  #3: core-time ..................   Passed    4.46 sec
1>        Start  4: core-misc
1>   4/11 Test  #4: core-misc ..................   Passed    0.09 sec
1>        Start  5: conf-encoding
1>   5/11 Test  #5: conf-encoding ..............   Passed    0.20 sec
1>        Start  6: conf-loader
1>   6/11 Test  #6: conf-loader ................   Passed    0.06 sec
1>        Start  7: conf-arch
1>   7/11 Test  #7: conf-arch ..................   Passed    0.07 sec
1>        Start  8: conf-components
1>   8/11 Test  #8: conf-components ............   Passed    0.13 sec
1>        Start  9: conf-proc
1>   9/11 Test  #9: conf-proc ..................   Passed    0.18 sec
1>        Start 10: conf-time
1>  10/11 Test #10: conf-time ..................   Passed    0.07 sec
1>        Start 11: conf-env
1>  11/11 Test #11: conf-env ...................   Passed    0.04 sec
1>
1>  100% tests passed, 0 tests failed out of 11
1>
1>  Total Test time (real) =   5.50 sec
======= Build: 1 succeeded, 0 failed, 1 up-to-date, 0 skipped =======
\end{verbatim}
\caption{Test output from CTest \cite{CMake:CTest} from Microsoft Visual Studio Community 2015 for procsim.}
\label{lst:cross-platform:ctest-output}
\end{listing}  

All of these build improvements worked towards improving software maintainability of the simulation suite. Whilst these changes do not directly contribute to the Problem Statement in \cref{sec:problem-statement}, it is patently obvious that improvements in developer work flow have a direct consequence in improvements to developer time utilization and reduces the likelihood of poor software being produced. Given improvements to developer productivity, one may argue simply that this improves the validity of producing modern software (\cref{req:modern}) and any software produced will more accurately meet requirements specified \cite{Solis2011}. As such, these improvements allowed us to develop procsim more rapidly and reduced time spent fighting against compilers and cross-platform development issues.