\chapter{Lua-based configuration-driven processor simulation}
\label{ch:lua}

\newcommand{\luainline}[1]{\mintinline{Lua}{#1}}

 From working with Scala-based configurations in \cref{sec:sec:procsim-scala:configuration}, we believed that runtime-configuration was extremely important in encouraging students to try and manipulate processor designs. The author chose to expand the hc12sim project's the JSON-based, compile-time configuration capabilities replacing the mechanism with runtime-based configurations utilizing an embedded scripting language. Within the C++ programming ecosystem, there exists many different scripting environments that can be embedded with varying degrees of difficulty, feature capabilities and execution speeds. The author investigated utilization of several scripting environments before settling on utilizing Lua \cite{Lua:Homepage} with bindings provided through sol2, a wrapper between C++ and Lua API calls \cite{GitHub:ThePhD:sol2}. Once Lua was selected, the author designed configuration schemas built to execute in a Lua sandbox with timing and other hardware-level considerations abstracted away from the configuration definitions as much as possible.

\section{Utilizing runtime configurations through scripting}

procsim.scala had a VHDL-like syntax for defining instructions within a processor simulation. Providing the same facilities within a non-managed language like C++ is not possible without the use of a scripting engine. When researching possible solutions to this problem, several scripting languages stood out: Python \cite{Python:Homepage}, JavaScript through Google's V8 \cite{Google:V8} or Mozilla's SpiderMonkey \cite{MDN:SpiderMonkey}, Lua \cite{Lua:Homepage}, or reusing Scala through the Java Native Interface (JNI) \cite{Oracle:JNI}.

\subsection{Scripting language selection}

\subsubsection{Python} 

Several scripting languages were evaluated against each other for candidacy as the configuration specification language. First, Python was considered \cite{Python:Homepage}. Python is a mature, stable, dynamically typed language with wide use in industry, scientific and academic communities \cite{StackOverflowSurvey2016}. Python was considered due to its exposed foreign function interface (FFI) which allows for C functions to be called from Python or C functions to call into Python. Python's syntax supports overriding operators \cite{Python:Operators}, object-oriented programming \cite{Python:Classes} and low-level bitwise operations \cite{Python:BuiltinTypes} -- features excellent for implementing low-level hardware simulations and configurations. For working with the Python VM, the Python community provides a library called CFFI that wraps python's FFI interface to call into and from Python. CFFI's purpose is to provide a bridge layer between Python and C easing the effort required. Any library wishing to utilize CFFI for interacting with the Python engine requires all exposed functions in the foreign library are externalized as C functions. procsim heavily employed C++11 syntax and does easily extend to a C-based API through its use of \cxxinline{template}, \cxxinline{inline} functions and \cxxinline{constexpr} values or functions. Thus porting procsim's API as a C API to utilize CFFI would become tedious. 

An alternate to the CFFI library is Boost.Python which provides binding mechanisms for working with complex classes in C++ and having them work within the Python virtual machine \cite{Boost1.53.0:Python}. Boost.Python provides a very simple and easy to use syntax for defining types. Further, Boost.Python respects \cxxinline{constructor} and \cxxinline{destructor} semantics of any types passed into Python. \Cref{lst:lua:python-example} showcases a simple type exposed into Python. Given the simplicity of exposing data into Python, and the ubiquitous nature of the language, it lends itself well to a pedagogical application (\cref{req:pedagogical}) and will feel modern to students coming from Software Engineering contexts (\cref{req:modern}). Regrettably, the largest compelling argument against Python is that to run Python scripts, one must install a Python virtual machine adding an extra dependency that is external to the project. This makes distribution more difficult for personal computers, though not all as some operating systems come with python pre-installed (e.g. most Linux distributions and macOS).

\begin{listing}[hp!]
\begin{minted}{C++}
// Simple Structure
struct World
{
    World(std::string msg): msg(msg) {} 
    void set(std::string msg) { this->msg = msg; }
    std::string greet() { return msg; }
    std::string msg;
};
\end{minted}

\begin{minted}{C++}
#include <boost/python.hpp>
using namespace boost::python;

// Define a python module
BOOST_PYTHON_MODULE(hello)
{
    class_<World>("World", init<std::string>())
        .def("greet", &World::greet)
        .def("set", &World::set)
        ;
}
\end{minted}

\begin{minted}{python}
>>> import hello
>>> planet = hello.World('hello')
>>> planet.greet()
'hello'
>>> planet.set('howdy')
>>> planet.greet()
'howdy'
\end{minted}
\caption{Example of exposing a C++ class to Python \cite{Boost1.53.0:Python}.}
\label{lst:lua:python-example}
\end{listing}

\subsubsection{JavaScript}

JavaScript is by far the most popular language in use in modern applications \cite{StackOverflowSurvey2016}. JavaScript provides many of the same features as Python, but does not have as ``strong'' of a type system. JavaScript provides many coercions of types into other types making it difficult to reason at times compared to Python (e.g. \mintinline{JavaScript}{{} + [] === 0} for reasons outside the scope of this document). While providing a modern interface for students (\cref{req:modern}), it also creates a regrettable pedagogical experience due to the extremely high-level nature of the language for low-level implementations (\cref{req:pedagogical}). In order to embed JavaScript within an application, it requires a JavaScript Virtual Machine to be embedded. The two current leading JavaScript engines are Google's V8 \cite{Google:V8} powering Google Chrome and Mozilla's SpiderMonkey \cite{MDN:SpiderMonkey} for Mozilla Firefox. SpiderMonkey provides a C++ API to embed functions and values into the engine. This C++ API is very similar to the API provided by Python's CFFI, however it provides slightly stronger type safety than a traditional C API utilizing \cxxinline{void*} arguments. When investigating to integrate the SpiderMonkey VM into procsim, an adverse design of SpiderMonkey is that the VM's entire state is bound to a single thread of execution \cite{MDN:SpiderMonkey:UserGuide}. JavaScript itself is a single-threaded language which is largely inconsequential for configuration declaration. Though due to SpiderMonkey itself being bound to a single thread, it may become too difficult to efficiently produce multi-threaded software when accessing SpiderMonkey JavaScript code at runtime. 

Google's V8 JavaScript engine is the most commonly used JavaScript engine as it powers Node.js, all Chromium-based browsers and Electron-based applications \cite{Google:V8}. Embedding V8 is a difficult task requiring large amounts of ``glue'' code to bind components \cite{Google:V8:Embedding}. Unlike SpiderMonkey, Simplified Wrapper Interface Generator (SWIG) provides a V8 wrapper \cite{SWIG:Homepage}. However, direct utilization of the V8 API is recommended. To use V8 in an application, it must be built and the library contains non-trivial build process per platform. Removal of non-trivial built libraries were removed as part of the work for \cref{sec:cross-platform:sec:modernizing}, thus adding a new complicated library proves contradictory to efforts previously made. To avoid the complicated build steps, for users to utilize V8 within procsim the entire engine would need to be shipped with the application or installed by users. Providing a working ``drop-in'' source for V8 or SpiderMonkey is unfortunately not feasible. As such, utilizing V8 or SpiderMonkey is not advantageous for procsim as an JavaScript is too high-level and the available engines are too large with large build dependencies.

\subsubsection{Java and Scala}

Java and Scala both require the Java Virtual Machine to execute software. Any application that has a JVM requirement involves either 1) packaging and shipping the entire JVM with the application or 2) expecting the user has a correctly installed JVM in default location. Both of these dependency resolution schemes for the JVM are difficult to complete with absolute certainty, but are not impossible. The JVM itself is also several hundred mebibytes in size with a large runtime overhead. We considered integration with the JVM because we had the existing DSL created within the procsim.scala project with a VHDL-like syntax that we could reuse. In order to access Scala or Java libraries outside the JVM, software wrappers must be written to utilize the Java Native Interface (JNI) \cite{Oracle:JNI}. The JNI is notoriously frustrating to write software for because C/C++ is not a managed language and the JVM is a managed VM making memory guarantees frustrating to correctly implement. Additionally, the JNI was developed to be efficient for software to communicate between two environments, it was not written to allow the process to be easy. Java developers are now discouraged from writing native libraries that interact with Java where possible as the JVM has significantly improved performance characteristics eliminating the largest use case for native libraries. SWIG provides an excellent wrapper definition tool to generate bindings for C++ classes into the JNI \cite{SWIG:Homepage} allowing developers to write generator files using a C++-like syntax which includes extra meta-information that is added to appease the Java Virtual Machine \cite{SWIG:Java}. SWIG uses ``directives'' to annotate existing C/C++ code to generate efficient JNI code that can then be compiled into a C/C++ application as any other software. SWIG does not support method references or lambda expressions which proved problematic when developing a communication layer. In addition, working with SWIG wrappers it non-trivial as classes become more complicated. SWIG has not updated over time to keep up with C++ standards and does not directly support many semantics such as \cxxinline{std::unique_ptr} and lambda expressions. With the additional overhead of utilizing the JVM, reusing the older procsim.scala DSL is not feasible as an embedded scripting language. Java is not designed to be embedded. Java was designed to be it's own managed runtime and have foreign native code be given selective access to run within the JVM. Due to large overhead costs at both build and runtime, we discarded Java as a viable scripting language.

\subsubsection{Lua}

Lastly, the Lua programming language was considered as it is by design an embedded scripting language \cite{Lua:Homepage}. The Lua Programming Language home page directly states: 
\begin{displaycquote}{Lua:Homepage}
    Lua is a powerful, efficient, lightweight, embeddable scripting language. It supports procedural programming, object-oriented programming, functional programming, data-driven programming, and data description.
\end{displaycquote}
\noindent These features fully encompass those features previously provided by Python while adding additional simplicity. Lua places data description as a first order citizen allowing for extremely descriptive dictionaries of heterogeneous data \cite{Ierusalimschy:PIL}. Similar to JavaScript's Object, Lua provides traditional object-oriented programming through an associative arrays known as tables \cite{MDN:Object, Ierusalimschy:PIL}. \Cref{lst:lua:project-example} shows a simple dictionary-like description of a ``project entry'' that the Lua community uses to display known projects that use Lua \cite{Lua:WhereIsLuaUsed}. Creating tables in Lua are a trivial task and through external libraries, such as tableshape, the schema or ``shape'' of a table can be quickly validated \cite{GitHub:leafto:tableshape}. 

Lua's design is first and foremost an embedded scripting language. Interaction with Lua's VM is through direct calls to Lua's C API. Many wrapper generation tools exist to allow higher-level binding than hand-written C API calls. SWIG provides a wrapper for Lua, but it has the same concerns as the Java generator discussed previously. For wrapping the procsim library, we considered sol \cite{GitHub:Rapptz:Sol} and luacppinterface \cite{GitHub:davidsiaw:luacppinterface} as they provided the best integration with C++ at the time. Both sol and luacppinterface provided tested interfaces for working with the Lua VM from C++, however sol provided more modern bindings for emerging C++ standards. Lua's syntax is very similar to other C-style languages and is commonly utilized in games world-wide showcasing the modern nature and performance characteristics of Lua (\cref{req:modern}). In addition to the traditional Lua engine, there is a hand-written JIT version of Lua known as LuaJIT. LuaJIT is extremely fast and provides machine-compiled Lua scripts at execution. Further, LuaJIT's C API is a superset of Lua's meaning it is fully compatible. 

Lua's syntax is extremely simple but provides flexibility with the ability to override all operators. This meant that the style of configuration intended for use with procsim.scala could be roughly ported to use within a Lua environment. When defining configurations, Lua is still a full programming environment with all of the power of a programming language adding a new layer to configuration capabilities for \cref{req:configuration}. Lastly, through LuaJIT, Lua is the near best performing scripting language after JavaScript. Lua provides a very simple interaction point thanks to wrapping libraries and Lua's embedding first design philosophy leaves it small, unbloated and easy to compile and package. 

\begin{listing}[t!]
\begin{minted}{Lua}
entry {
    title = "Tecgraf",
    org = "Computer Graphics Technology Group, PUC-Rio",
    url = "http://www.tecgraf.puc-rio.br/",
    contact = "Waldemar Celes",
    description = [[
        TeCGraf is Lua's birthplace,
        and the language has been used there since 1993.
        Currently, more than thirty programmers in TeCGraf use
        Lua regularly; they have written more than two hundred
        thousand lines of code, distributed among dozens of
        final products.]]
}
\end{minted}
\caption{Table used to describe project information for the Lua.org site \cite{Ierusalimschy:PIL}}
\label{lst:lua:project-example}
\end{listing}

\subsubsection{Scripting language decision}

After consideration of the four different scripting languages, it was narrowed to a choice between Lua and Python. Boost.Python's long history of use coupled with existing Boost usage in procsim made Python an enticing option. In addition, Python's feature set is very complete for most of the known use cases for procsim's configuration design requirements. A large issue with Python was that Boost.Python proved to be non-trivial to cross-compile on multiple platforms and imposed a direct coupling to the sizeable Python runtime. Further, to have simple configurations \mintinline{python}{dict} literals are required which provides less type safety guarantees than Lua's equivalent through tables validated with tableshape \cite{Python:BuiltinTypes, Ierusalimschy:PIL, GitHub:leafto:tableshape}. Lastly, Python's garbage collection can become difficult to work with in a non-managed language as it was not built with embedding in mind. Lua's focus on embedded scripting interfaces; its wide-spread use in games and industrial software as a scripting interface; the simplicity to build the C-based JIT or interpreted VM; and data description capabilities drove the decision to utilize Lua for configuration within procsim. 

\subsection{Lua integration}

Once Lua was chosen as a scripting language, the task of integrating the language into procsim's existing object model arose. As stated previously, there existed two main projects under consideration for wrapping C++ API into a scripting engine: luacppinterface and sol \cite{GitHub:davidsiaw:luacppinterface, GitHub:Rapptz:Sol}. When first attempting to implement a scripting interface, luacppinterface was chosen because it was simpler than sol. However due to the simple features available and the API design of luacppinterface, binding large \cxxinline{class} instances became overly complicated and runtime performance severely degratted. Thus, we migrated the software to sol. sol provided an elegant and still relatively simple C++11-based interface to wrap classes and functions to expose them to a Lua environment without the use of problematic C-style macros at zero runtime overhead cost \cite{GitHub:Rapptz:Sol}.

When working with sol, several bugs were found in the implementation of the wrapper. Of significant importance was in sol's current state, it could not pass a table to a C++ constructor \cite{GitHub:Rapptz:Sol:74} -- a feature we planned on utilizing heavily. This author raised the issue and after several weeks of remaining open, the author of sol never responded. However, another GitHub user by the name of ``ThePhD'' revived the project under a new name, sol2 (herein referred to as sol) \cite{GitHub:ThePhD:sol2}. sol was updated to include support for C++14 features and heavily relied on inline variadic template functions and SFINAE structures \cite{cppreference:SFINAE} to provide extremely efficient zero-cost bindings to Lua in a clean elegant syntax \cite{GitHub:ThePhD:sol2:benchmarks, GitHub:ThePhD:sol2:cxx-in-lua}. In \cref{lst:lua:sol2-example:player,lst:lua:sol2-example:usage,,lst:lua:sol2-example:bindings} sol2's capabilities are shown to simply bind the \cxxinline{class player} into Lua and utilize it within a simple toy script. Binding class properties is provided by utilizing \cxxinline{sol::property(...)} and \cxxinline{sol::readonly(...)} allowing a pattern very similar to Java Bean properties \cite{Oracle:JavaTutorial:JavaBeans}. The flexibility of overriding the operations allows for the creation of new ``syntax-like'' changes that alter the traditional behaviour of Lua operations as done with procsim.scala. While overloading operators is something heavily debated, the intention of changing ``typical'' behaviours is to reduce the amount of effort required by students. If the reading context remains consistent with traditional behaviour, a transparent side-effect should not increase the amount of knowledge required to use the system. The Java-bean style ``getter'' and ``setters'' let developers add or change side-effects of how an action works transparently to users. Without the wrappers provided by sol, this task is very difficult as it involves manually modifying Lua's meta-tables \cite{GitHub:ThePhD:sol2:usertype}.

\begin{listing}[hp]
\begin{minted}{C++}
class player {
public:
    int bullets;
    
    player(): player(3) 
    { }
    
    player(int ammo)
        : bullets(ammo), hp(10)
    { }
    
    bool shoot () {
        if (bullets < 1) 
            return false;
    
        --bullets;
        return true;
    }
    
    void set_hp(int value) {
        hp = value;
    }
    
    int get_hp() const {
        return hp;
    }
    
private:
    int hp;
};
\end{minted}
\caption{\cxxinline{class player} that holds two fields, one for hitpoints (\cxxinline{hp}) and one for bullets a player has (adapted from \cite{GitHub:ThePhD:sol2:cxx-in-lua}).}
\label{lst:lua:sol2-example:player}
\end{listing}

\begin{listing}[hp]
\begin{minted}{Lua}
-- player_script.lua

-- call single argument integer constructor
p1 = player.new(2)

-- p2 is still here from being
-- set with lua["p2"] = std::make_shared<player>(0);
-- in cpp file
local p2shoots = p2:shoot()
assert(not p2shoots) -- had 0 ammo

-- set variable property setter
p1.hp = 545;
-- get variable through property getter
print(p1.hp);

local did_shoot_1 = p1:shoot()
print(did_shoot_1)
print(p1.bullets)
local did_shoot_2 = p1:shoot()
print(did_shoot_2)
print(p1.bullets)
local did_shoot_3 = p1:shoot()
print(did_shoot_3)

-- can read
print(p1.bullets)
-- would error: is a readonly variable, cannot write
-- p1.bullets = 20
\end{minted}
\caption{Utilize the \cxxinline{class player} within a Lua script (adapted from \cite{GitHub:ThePhD:sol2:cxx-in-lua}).}
\label{lst:lua:sol2-example:usage}
\end{listing}

\begin{listing}[hp]
\begin{minted}{C++}
#include <sol.hpp>

int main () {
    sol::state lua;
    
    // Register usertype metatable
    lua.new_usertype<player>( "player",
        // 2 constructors
        sol::constructors<player(), player(int)>(),
        
        // member function that returns a variable
        "shoot", &player::shoot,
        
        // gets or set the value using member variable syntax
        "hp", sol::property(&player::get_hp, &player::set_hp),
        
        // can only read from, not write to
        "bullets", sol::readonly( &player::bullets )
    );
    
    // set a variable "p2" with a new "player" with 0 ammo
    // using an std::shared_ptr<>
    lua["p2"] = std::make_shared<player>(0);
    
    // run the example script
    lua.script_file("player_script.lua");
    
    const std::shared_ptr<player> p1 = lua["p1"];
    std::cout << p1->hp << std::endl; // prints 545
}
\end{minted}
\caption{Required bindings to allow utilization of \cxxinline{class player} from Lua (adapted from \cite{GitHub:ThePhD:sol2:cxx-in-lua}).}
\label{lst:lua:sol2-example:bindings}
\end{listing}

Working with sol was not entirely without problems. Because sol was actively developing, we worked closely with the new author of sol, ``ThePhD,'' to implement features and verify behaviours across multiple platforms (a requirement deeply discussed within \cref{sec:cross-platform:sec:cross-platform-development}). We implemented tests and benchmarks on the macOS platform as ``ThePhD'' did not have access to the platform. We worked to add continuous integration support for sol through Travis-CI \cite{TravisCI} to confirm the libraries support on platforms required for procsim \cite{GitHub:ThePhD:sol2:pr:17, GitHub:ThePhD:sol2:pr:18}. The contributions surrounding continuous integration improvements were re-purposed configurations from procsim provided as open-source contribution to sol. Within procsim, the development heavily tracked the cutting-edge of sol development. By tracking sol closely, performance fixes and improvements were rapidly integrated into our implementation. Problematic ergonomics were discussed and often implemented and a symbiotic relationship was built that benefited implementation of procsim and sol. 

\subsection{Configuration versus Simulation entities}
\label{sec:lua:sec:configuration-vs-simulation}

The original hc12sim project shared all modules between both configuration and simulation. This meant less lines of code to understand and generally made the software ``easier'' to write for novice developers. However as modules grow in size, they become more complicated to maintain. Something found in work for \cref{ch:scala-akka} was that immutable objects produce easier to reason and better performing software. In developing configuration entities to specify simulation entities, it was found that a lot of meta-information required to make configurations easier to specify could be removed once the system was fully specified. The meta-information was provided to students to reduce their cognitive load but does not provide value to a simulation. Most values within the configuration entity need to be mutable within a configuration file, but within the simulation these values are immutable allowing for simpler testing of a simulation engine.

For example, when defining a \texttt{Register} component, there are a several values that are required when configuring an instance: 
\begin{itemize}
\item name - A logical name
\item clock - The clock that this Register is bound to (Registers are sequential)
\item readCount - Number of clock ticks this takes to read a value (required to ``slow'' down execution)
\item writeCount - Number of clock ticks to write a value to the Register
\item access - What type of access this register supports, i.e. read or write
\end{itemize}
When writing a configuration, the it is easier to define a \texttt{clock} by its name, a literal definition or by utilizing a \luainline{local} value. By contrast, at simulation time the \texttt{clock} must be a reference to an existing instance from somewhere. This idea of ``higher-level configuration'' that is transformed into a ``lower-level'' representation directly mimics a compiler's approach when compiling high-level code to the compiler's intermediate representation. The intermediate representation removes superfluous information in exchange for a smaller but easier to optimize representation of the programs state which is how simulation entities are represented. We have included most of the class definitions for simulation entities in \cref{ch:procsim-sources}.

% We removed half of these parameters from the ts version -- they have no use when you are treating everything
% as I/O connections, they just aren't necessary. Want a read-only register? Don't connect something to D.


\section{Lua-based Configuration}

To limit the scope of a system's configuration, procsim only exposes the following components: registers, memory banks (ROM, RAM), clocks, and arithmetic operations. Simplification of the model allows for reduction of complexity in an attempt to reduce the cognitive load for students when creating their own processors, similar to the approach taken by \cite{Skrien2001} and \cite{Garcia2009}. This trade-off removes excessive modules in favour of simplifying interfaces to improve pedagogical outcomes (\cref{req:pedagogical}). The minimal canonical example of a Turing-complete machine is URISC, popularized by \cite{Mavaddat1988} and \cref{fig:urisc-architecture} shows the hardware architecture of URSIC which \cref{lst:lua:urisc-example-1,lst:lua:urisc-example-2} was based off of which we use as a referential base for configuration specifications.

\begin{figure}[bp!]
    \centering
    \includegraphics[width=0.5\linewidth]{img/urisc-architecture}
    \caption{URISC hardware architecture with microcodes \cite{Mavaddat1988}.}
    \label{fig:urisc-architecture}
\end{figure}

\begin{listing}[hp!]
    \inputminted[escapeinside=||, lastline=42]{lua}{./listings/urisc.lua}
    \caption{Configuration of \cref{fig:urisc-architecture} for the URISC processor \cite{Mavaddat1988}.}
    \label{lst:lua:urisc-example-1}
\end{listing}

\begin{listing*}[hp!]
    \inputminted[escapeinside=||, firstline=43]{lua}{./listings/urisc.lua}
    \caption{(Continued) Configuration of \cref{fig:urisc-architecture} for the URISC processor \cite{Mavaddat1988}.}
    \label{lst:lua:urisc-example-2}
\end{listing*}

Because procsim's configurations are written in Lua, they are fully Lua compliant scripts in every aspect. In \cref{lst:lua:urisc-example-1} on line 4, a local variable is defined that is used throughout the processor definition. While defining a numerical value of four is trivial, this potential expands to allow for definitions that include loops and other control flow statements to simplify definitions of large or iteratively built module configurations. This mechanic defines why these configurations are so powerful, the example of a variable declaration is a shamefully inadequate description. The idea to utilize Lua as a means of ``configuration as code'' was inspired by previous work with Google Guice through its \javainline{Module<T>} syntax \cite{Google:Guice:Motiviation} and annotation driven serialization with Jackson Annotations \cite{GitHub:Jackson:Annotations}.

We use the Lua scripting engine to directly execute a specified configuration as a Lua script. When the script executes, it must create and return a \luainline{Proc} instance. While the script executes, any instantiations of types are projected through Lua into the C++ configuration entities as described in \cref{sec:lua:sec:configuration-vs-simulation}. These entities have properties that can be easily read and reused within a configuration script. Once the full configuration is returned, the \luainline{Proc} and it's children must be converted into near-immutable simulation entities. We have included the definitions of the simulation classes within \cref{ch:procsim-sources}. We elaborate on how each of these configuration entities are defined within configurations in further discussions.

Moving further into the URISC example in \cref{lst:lua:urisc-example-1,lst:lua:urisc-example-2}, all objects use a static \luainline{new} method that accepts a Lua table of configuration values. This approach was utilized to mimic JavaScript's colloquially named ``option object'' of parameters to make parameter values as obvious as possible by using explicit keys. For each table-based function, the keys and values are validated against an expected schema -- invalid or missing keys or bad value types throw informative exceptions for students to recover from. All instances within the configuration schema inherit from \cxxinline{class ConfObj} which defines that every instance must have a name. These names are utilized to lookup references in other referenced modules. From these names, the ``compilation'' of the configuration utilizes a two-phase compilation pattern inspired by a typical assembler pattern. The first phase runs across the entire structure and creates a list of required references attempting to verify any named reference has an associated configuration object. This table of references are sorted using a topological ordering such that every module is built before it is required. Each configuration value is converted through sol2 bindings to create non-configuration entities 

\paragraph{Clock.} Breaking down each component type, first is definition of a \luainline{Clock}, repeated in \cref{lst:lua:urisc:clock}. \luainline{Clock} modules must have a \luainline{:period} or \luainline{:frequency}\footnote{In Lua, the object method invocation syntax is: \luainline{object:method} which passes \texttt{object} as the \texttt{this} parameter. For the remainder of this document, the \texttt{this} parameter is omitted for brevity and is implied when prefaced by \texttt{:}.} -- defining one implies the other. These each have useful ``helper'' functions that allow for defining relative values. For \luainline{:period}, the helper functions: \luainline{seconds()}, \luainline{millis()}, \luainline{micros()} and \luainline{nanos()} define times relative to nanoseconds. For \luainline{:frequency} the style of functions exist based on Hertz (e.g. \luainline{MHz()}, or \luainline{KHz()}). These \luainline{Clock} modules generate instances that produce ``tick'' operations based on the \luainline{:period} and allow synchronous modules to listen for events. 

\begin{listing}[h!]
    \inputminted[escapeinside=||, firstline=10, lastline=13]{lua}{./listings/urisc.lua}
    \caption{\luainline{Clock} configuration for the processors main clock (cut from \cref{lst:lua:urisc-example-1}).}
    \label{lst:lua:urisc:clock}
\end{listing}

\paragraph{Register.} In procsim, a \luainline{Register} is a simple memory unit that stores a single value. The \luainline{PC} definition is shown in \cref{lst:lua:urisc:register}. The \luainline{:width} parameter represents the bit-width of the \luainline{Register}'s stored value. \luainline{access} is a set of enumeration values that are used to define ``getter'' and ``getter'' methods for the ``value'' of a \luainline{Register}. If the \luainline{:access} parameter is \luainline{Access.ReadWrite} then the value may be set or read. Alternately if the \luainline{access} for an example \luainline{Register} \luainline{R} is \luainline{Access.Write} then the following instruction code will not compile in the Lua interpreter: \luainline{local r_plus_1 = proc.R + 1}. By setting the \luainline{:access} to \luainline{Access.Write} the value can not be read from the register -- effectively disconnecting the \verb|Q| signal in traditional \luainline{Register} diagrams. procsim achieves this behaviour by not binding a ``setter'' or any arithmetic operations for the \luainline{Register} type bound through sol to the property for \luainline{proc.R} parameter utilized when defining an \luainline{Instruction} execution (see \cref{sec:lua:sec:instructions:sec:exec}). The \luainline{:readCount} and \luainline{:writeCount} parameters define how many clock ``ticks'' it takes to read or write to the \luainline{Register} respectively. These values are utilized by the execution engine to schedule the triggering of events.

\begin{listing}[th!]
    \inputminted[escapeinside=||, firstline=17, lastline=23]{lua}{./listings/urisc.lua}
    \caption{\luainline{Register} configuration for the program counter (cut from \cref{lst:lua:urisc-example-1}).}
    \label{lst:lua:urisc:register}
\end{listing}

\paragraph{Memory.} The second last module type available are \luainline{Memory} units. \luainline{Memory} are either read-only or read-write like \luainline{Register} values. \Cref{lst:lua:urisc:memory} shows the RAM definition for the URISC architecture. Parameters are identical to a \luainline{Register} except that they additionally have a \luainline{:length} parameter that defines the length of a \luainline{Memory} in units of \luainline{:width} (the word width). In the sample, the memory is 16KiB ``words'' wide. With a RAM, depending on the type of memory being modelled, it is often useful to have the \luainline{:clock} parameter be slower than the processor clock. This models the exponentially different time taken to read from a \luainline{Register} rather than cache or off-chip memory.

\begin{listing}[h!]
    \inputminted[escapeinside=||, firstline=35, lastline=42]{lua}{./listings/urisc.lua}
    \caption{Memory unit configuration for the program counter (cut from \cref{lst:lua:urisc-example-1}).}
    \label{lst:lua:urisc:memory}
\end{listing}

\paragraph{Proc.} The second last module defined is the processor itself through the \luainline{Proc.new()} function. The \luainline{:clock} parameter defines the clock utilized by the processor itself. This value is not shared amongst internal modules unless explicitly named by another module. The \luainline{:registers} table defines \luainline{Register} values that live ``on-chip'' within the created \luainline{Proc}. The \luainline{:memory} table defines a sparse-matrix representation of the processor's memory mapping. Any inline defined \luainline{Memory} or \luainline{Register} components are given the name of the key in the table they are specified in. This is a small convenience for students to not replicate information which risks typographic mistakes. Within the \luainline{:memory} map, any memory unit may be defined at an ``address'' specified. In the URISC machine, there are no memory mapped registers, however \cref{lst:lua:memory-mapped} displays a small processor with three \luainline{Register} values mapped to the first three addresses and a RAM mapped starting at address \luainline{0x0004}. Specification of \luainline{:memory} mappings take into account the width of the memory elements specified and will do partial reads or writes depending on what is required. The current implementation does not support memory elements smaller than the word size. The \luainline{:instructions} table provides a look-up table of instruction information including execution patterns for an \luainline{Instruction}. \luainline{Instruction} definitions are discussed in the next section, \cref{sec:lua:sec:instructions}.

\begin{listing}[hp!]
    \inputminted[escapeinside=||]{lua}{./listings/memory-mapping.lua}
    \caption{Processor utilizing memory mapping functionality.}
    \label{lst:lua:memory-mapped}
\end{listing}

\section{Instruction definition}
\label{sec:lua:sec:instructions}

The \luainline{Instruction} definition is more complicated than any other module and where the best benefits are found from a programmatic configuration. Within the \luainline{proc:instructions} table, the \luainline{:name} of the \luainline{Instruction} is calculated based on the value of the key an \luainline{Instruction} is assigned to, mimicking the \luainline{proc:registers} table. 

\subsection{Opcode and Operand encoding}

procsim allows for easily defining complex encodings for opcode and operand values. \\* \luainline{Instruction:code} specifies the opcode of an \luainline{Instruction}. A \luainline{Code} definition describes values encoded within an opcode a traditional microarchitecture. \Cref{lst:lua:urisc:encoding} shows a cut of the encoding definition for the URISC \texttt{SUBLEQ} \luainline{Instruction}. Within the \luainline{:code} parameter, the \luainline{Code} construct defines an opcode. The first parameter of \luainline{Code}'s constructor is a constant value with bits that remain constant in all encodings of the current instruction -- both high and low values are. The second parameter is a table of ``fields'' that are encoded within the opcode when compiled. Any key passed into the table will be extracted from the opcode at decoding time and passed into the execution handler attached as an ``operand field.'' With both the constant opcode and the table of fields, \luainline{Code.new{}} calculates the constant bits of the opcode encoding. Once all \luainline{Instruction} values are defined for a \luainline{Proc}, the configuration engine computes a discriminant decoding schema for runtime. When defining a field, there are several helper functions in use. Line 51 of \cref{lst:lua:urisc:encoding} includes the helper function, \luainline{u16(15)} which creates an unsigned 16-bit field at index 15\footnote{While Lua uses a 1-based indexing scheme like MATLAB or FORTRAN, procsim uses zero-based indexes to match C.}--indexed from the least-significant bit to the most-significant bit. The naming scheme for the primitive field helper functions are named using the Rust programming language's names for primitive types as they are short and unambiguous in their context \cite{Rust:PrimitiveTypes:Numeric}.

\begin{listing}[hb!]
    \inputminted[escapeinside=||, firstline=48, lastline=59]{lua}{./listings/urisc.lua}
    \caption{Encoding of the opcode and operands of the \texttt{SUBLEQ} \luainline{Instruction} (cut from \cref{lst:lua:urisc-example-1}).}
    \label{lst:lua:urisc:encoding}
\end{listing}

The decoding scheme for a processor specification is computed from the table of \\* \luainline{Instruction}s in \luainline{Proc:instructions} by computing individual discriminants per instruction and then cross-checking each discriminant against other instructions in a pair-wise fashion. To check if two discriminants are ambiguous, mask each ``constant'' opcode with another's ``constant mask'' and vice versa and if the resultant values are equal, the constant values are equal implying there is an ambiguous opcode specified. \Cref{alg:lua:opcode-verification} details the full computation used to verify ambiguous opcode specifications. If an ambiguous opcode is found within the instruction table an exception is thrown alerting the user which instructions have ambiguous conflicts and which constant bit values are shared. Unfortunately, this verification algorithm operates in a $\text{O}(n^2)$ complexity as each operation must be compared to another. A solution utilizing a radix-based sort could reduce the search space for each constant operand to make the algorithm $\text{O}(n \log n)$ \cite{Goodrich2014} -- though the complexity of each step within this computation is of trivial time due to consisting of two bitwise operations, making the trade-off between readable and fast code inconsequential. This specification scheme for encoding allows for extremely flexible ISA design but also provides a mechanism to allow students to find and recover from mistakes. By using this simplistic specification system and providing feedback for students, students will have an easier time learning why certain ISA design schemes do not work. 


\begin{algorithm}[hp!]
    \caption{ISA opcode verification algorithm to find ambiguous opcode definitions}
    \label{alg:lua:opcode-verification}
    \begin{algorithmic}[1]
        \Statex \textbf{Input}: $ins$ = Array of Instruction definitions
        \Statex \textbf{Output}: Array of Instruction definition pairs with ambiguous opcode values.
        
        \Statex \textbf{Step 1: \emph{Compute a discriminant mask for each Instruction}}
        
        \State Define a buffer for computed discriminants and masks
        \State $insBuffer \gets \left[\right]$
        \ForAll{$i \in ins$}
            
            \State Build a mask for field location in the opcode
            \State $fieldMask \gets 0$
            \\
            \ForAll{$field \in i.fields$}
                \State Compute the field's bit mask
                \State $currentMask \gets \left( \text{mask}\left( field.width \right) \ll field.index \right)$
                \\
                \State Mask the current field's mask with the overall field mask
                \State $fieldMask \gets field.mask \mathrel{|} currentMask$
            \EndFor
            \\
            \State Compute the constant bits of the opcode, bits that are not part of fields
            \State $opcodeMask \gets \textbf{not}~fieldMask$
            \State $discriminant \gets ins.opcode$
            \\
            \State Store the discriminant and mask
            \State $insBuffer.push\left( \left[ins, disciminant, opcodeMask \right] \right)$
        \EndFor
        
        \Statex\textbf{Step 2: \emph{Use the computed masks to search for ambiguities}}
        \State $ambiguous \gets \left[\right]$
        \State Perform a cross-validation of Instruction values
        \ForAll{$[computed1,~index] \in insBuffer$ }
            \ForAll{$computed2 \in insBuffer\left[index+1:\right]$}
                
                \State Unpack the computed values
                \State $[ins1,~ discriminant1,~ opcodeMask1] \gets computed1$
                \State $[ins2,~ discriminant2,~ opcodeMask2] \gets computed2$
                \\
                \State Compute a combined opcode mask
                \State $cMask \gets opcodeMask1 \mathrel{\&} opcodeMask2$
                \If{$\left(discriminant1 \mathrel{\&} cMask\right) = \left(discriminant2 \mathrel{\&} cMask\right)$}
                    \State The two opcodes are ambiguous if equal
                    \State $ambiguous.push\left(\left[ins1, ins2, cMask\right]\right)$
                \EndIf
            \EndFor
        \EndFor
        
        \Return{ $ambiguous$ }
    \end{algorithmic}
\end{algorithm}

Operands for an \luainline{Instruction} are specified within the \luainline{:op} parameter table. \luainline{:op} accepts a table of key to field specifications that behaves identically to the second parameter of \luainline{Code.new()}. Unlike the \luainline{:code} parameter, there is no verification for operand values. Keys within the \luainline{:code} and \luainline{:op} tables are checked for uniqueness and Lua failed to compile if a table has non-unique keys. The table values are unioned and their widths are computed, storing the total size of the operand for encoding into machine code. As with \luainline{:code}, the keys are extracted and from the compiled encodings and passed to the execution function. 

\subsection{Instruction execution: Side-effect-based compilation}
\label{sec:lua:sec:instructions:sec:exec}

The intention of the \luainline{Instruction:exec()} function is to provide the schema for how an \luainline{Instruction} executes within the context of a simulated processor and operands passed. When students provide a \luainline{:exec()} method, they are not writing the function that will directly execute within the engine. procsim.scala discussed utilizing an event-based execution schema that behaved through message passing; the \luainline{:exec()} method describes a sequence of events that will register within an event queue when the \luainline{Instruction} is called. When defining the syntax, we attempted to simplify the logic behind defining \luainline{Instructions} by converting normal Lua-operations (e.g. arithmetic) into sequences of events instead. \Cref{lst:lua:urisc:exec} defines the execution of the very simple \texttt{SUBLEQ} instruction used in the URISC architecture. Executing the \luainline{:exec()} function performs a process akin to compilation using the state changes defined by the function itself and utilizing side-effect operations to ``collect'' the sequence of state changes within the function definition. This process allows the engine to compile the execution events through a sequential mechanism and create a state machine that behaves as a student describes it. This does not provide a fully-asynchronous behaviour like VHDL's connection syntax, but does allow an execution engine to decide how state changes are scheduled. The following sub-sections describe the Lua statements found within \cref{lst:lua:urisc:exec} and how they compile to scheduled events within procsim.  

\begin{listing}[h!]
    \inputminted[escapeinside=||, firstline=61, lastline=74]{lua}{./listings/urisc.lua}
    \caption{Execution definition for the \texttt{SUBLEQ} \luainline{Instruction} (cut from \cref{lst:lua:urisc-example-1}).}
    \label{lst:lua:urisc:exec}
\end{listing}

\subsubsection*{Assignment}
\label{sec:lua:sec:instructions:sec:exec:sec:Assignment}

An assignment statement, e.g. \luainline{proc.R = operand.A} is scheduled using \cref{alg:lua:assignment}. The right-hand side arguments is known as the \texttt{rval} which is treated as an rvalue in C++ terminology \cite{cppreference:ValueCategories}. The left-hand size argument is the value assigned to and is known as \texttt{lval} mimicking lvalue in C++ \cite{cppreference:ValueCategories}. When working with assignments, this event-based architecture allows a simulation engine to reorder assignments depending on how the execution will progress. This flexibility allows for implementations of optimization patterns at a future time. 

\begin{algorithm}[h!]
    \caption{Assignment statement compilation}
    \label{alg:lua:assignment}
    \begin{algorithmic}[1]
        \Statex \textbf{Input}: $rval$ = \texttt{rvalue} read from 
        \Statex \textbf{Input}: $lval$ = \texttt{lvalue} assigned to
        \Statex \textbf{Input}: $bus$ = Bus for data path
        \Statex \textbf{Side-effect}: Bus contains the value from $rval$
        \Statex% blank
        \If{$rval$ is an operand}
            \State Read the bit pattern from the decoded operands
            \State $bus \gets operand$
        \Else 
            \State Value is a module within the machine
            \State $bus \gets rval$
        \EndIf
        \\
        \State $lval \gets bus$
    \end{algorithmic}
\end{algorithm}

%\begin{enumerate}
%    \item Read the rvalue \cite{cppreference:ValueCategories} of the assignment onto a BUS
%    \begin{itemize}
%        \item if the rvalue is an operand, this value is read from the decoding sequence and written to the lvalue \cite{cppreference:ValueCategories} location.
%        \item Assignment statements may be rewritten depending on order of encoding operations if and only if the assignment has no side-effects in the state machine
%    \end{itemize}
%    \item Write the value from the BUS into the lvalue specified (i.e. \luainline{proc.R})
%\end{enumerate}

\noindent Lua's \luainline{local} variables are handled utilizing the result of any operations or assignments as a ``BusValue'' representing the state of the Bus in use rather than traditional \texttt{integer} values. For example, after an assignment, the result of an operation is a ``BusValue'' that states what is currently on the data bus if and only if the assignment is not a direct module lookup. For example, consider the following \luainline{local} assignments: 

\begin{listing}[h!]
\begin{minted}{lua}
-- Create an alias, B is proc:B
local B = proc:B

-- Create a `BusValue' that has the value of the operation B + A
local C = proc:B + proc:A

-- Use the value on the databus as the address into memory
-- And store the value of that address in that location
proc:memory[C] = C -- 'result' of this is a `BusValue' of C, still
proc:X = proc:A + proc:B -- 'result' of this is a `BusValue' 
                         -- with value proc:X
\end{minted}
\caption{Local variable definitions within an \luainline{Instruction:exec()} method.}
\end{listing}

\noindent Implicitly created ``BusValue'' semantics allow for code reuse within implementation definitions while remaining behaviourally accurate. \luainline{local} defined variables provide a simple way for students to write ``high-level'' code to simplify their implementations.

\subsubsection*{Memory Access}

Memory accesses, \luainline{proc.memory[B]}, read a memory location or write to it depending on whether the access is an lvalue or rvalue. In \cref{lst:lua:urisc:exec} on line 65, the memory access is used as an lvalue, and we utilize \cref{alg:lua:memory-access:read} to schedule the events.

\begin{algorithm}[h!]
    \caption{Memory read compilation}
    \label{alg:lua:memory-access:read}
    \begin{algorithmic}[1]
        \Statex \textbf{Input}: $memory$ = Memory unit to read from or write to
        \Statex \textbf{Input}: $address$ = address within $memory$
        \Statex \textbf{Input}: $abus$ = Bus for address path
        \Statex \textbf{Input}: $dbus$ = Bus for data path
        \Statex \textbf{Side-effect}: $abus$ contains $address$
        \Statex \textbf{Side-effect}: $dbus$ contains the value from $memory\left[address\right]$
        \Statex% blank
        \Statex Write the $address$ to $abus$
        \State $abus \gets address$
        \Statex Set $memory.readWrite$ to $READ$
        \State $memory.readWrite \gets READ$
        \\
        \Statex Memory buffer register gets the value at $memory\left[address\right]$ on $memory$ clock pulse
        \State $memory.buffer \gets memory\left[address\right]$
        \\
        \Statex Write result of read to $dbus$ on $dbus$ clock pulse
        \State $dbus \gets memory.buffer$
    \end{algorithmic}
\end{algorithm}

\noindent Alternately, \cref{alg:lua:memory-access:write} showcases the events triggered on writing a value to a location in memory such as \luainline{proc.memory[0x04] = proc.B}.

\begin{algorithm}[h!]
    \caption{Memory write compilation}
    \label{alg:lua:memory-access:write}
    \begin{algorithmic}[1]
        \Statex \textbf{Input}: $memory$ = Memory unit to read from or write to
        \Statex \textbf{Input}: $address$ = address within $memory$
        \Statex \textbf{Input}: $value$ = Value to write to $memory$
        
        \Statex \textbf{Input}: $abus$ = Bus for address path
        \Statex \textbf{Input}: $dbus$ = Bus for data path
        \Statex \textbf{Side-effect}: $abus$ contains $address$
        \Statex \textbf{Side-effect}: $dbus$ contains $value$ 
        \Statex \textbf{Side-effect}: $memory\left[address\right]$ contains $value$
        \Statex% blank
        
        \Statex Write the $address$ to $abus$
        \State $abus \gets address$
        \Statex Write $value$ to $dbus$
        \State $dbus \gets value$
        \Statex Set $memory.readWrite$ to $WRITE$
        \State $memory.readWrite \gets WRITE$
        \\
        \Statex $memory.buffer$ register gets the $value$ from $dbus$ on the $dbus$ clock pulse
        \State $memory.buffer \gets dbus$
        \\
        \Statex $memory$ writes $value$ to $address$ on $memory$ clock pulse
        \State $memory\left[address\right] \gets memory.buffer$
    \end{algorithmic}
\end{algorithm}

\noindent Once the memory access completes, the bus mechanics reuse the semantics outlined in the previous Assignment \cref{sec:lua:sec:instructions:sec:exec:sec:Assignment}.
    
\subsubsection*{Arithmetic Operations}

Arithmetic operations, e.g. \luainline{operand.B - proc.R}, happen through a single ALU within procsim's model. In the context of \cref{lst:lua:urisc:exec} line 65, when performing the subtraction ALU conditional bit flags based on the \hcmodel{} condition code flags are assigned by default to the \luainline{proc:C}, \luainline{proc:N}, and \luainline{proc:Z}. For multiplication or division operations, \luainline{proc:O} is also set. In the case of URISC, a manual ``buffer'' register of \luainline{proc:R} is utilized as the ``right-hand side'' of it's adder. In the ALU for procsim, both left and right side of a binary operation have ``buffer'' inputs that can be assigned. \Cref{alg:lua:arithmetic} shows the compilation steps for any ALU-based operation. The arithmetic application reuses the previously defined assignment semantics and memory access where required.

\begin{algorithm}[h!]
    \caption{Arithmetic operation compilation}
    \label{alg:lua:arithmetic}
    \begin{algorithmic}[1]
        \Statex \textbf{Input}: $lhs$ = Left-hand side argument
        \Statex \textbf{Input}: $rhs$ = Right-hand side argument
        \Statex \textbf{Input}: $operation$ = Arithmetic operation, e.g. $SUBTRACT$
        \Statex \textbf{Input}: $result$ = Result location
        \Statex \textbf{Input}: $dbus$ = Bus for data path
        \Statex \textbf{Input}: $alu$ = ALU module with condition bit flags
        
        \Statex \textbf{Side-effect}: $dbus$ and $result$ contain result of arithmetic operation
        \Statex \textbf{Side-effect}: $alu$ condition flags are set as appropriate
        \Statex% blank
        
        \Statex Using assignment semantics:
        \State $alu.lhs \gets lhs$
        \State $alu.rhs \gets lhs$
        \State $alu.operation \gets operation$
        \\
        \Statex Start operation
        \State $alu.start \gets START$
        \\
        \State Spin until operation completes, signalled via $alu.done$
        \State $alu$ condition bits are set to appropriate values per the operation
        \State $result \gets alu.result$
    \end{algorithmic}
\end{algorithm}

%\begin{spacing}{1.5}
%    \begin{enumerate}
%        \item Assign \luainline{proc.R} to the right-hand-side ``buffer'' of the ALU
%        \item Assign \luainline{operand.B} to the left-hand-side ``buffer'' of the ALU
%        \item Assign the ALU operation selection signal to ``subtract'' (add after two's complement of right-hand-side)
%        \item If and only if the value is assigned to an lvalue,
%        \begin{enumerate}
%            \item Assign the result of the subtraction result to the data bus
%            \item Store the data bus line value to the location of the lvalue
%        \end{enumerate}
%    \end{enumerate}
%\end{spacing}

\section{Project design and technical flaws}

\subsection{Compiler strain}

While utilizing Lua gave a massive boost in power, speed and functionality of runtime configuration over the previous hc12sim project and procsim.scala, it has large costs to developer productivity. With the amount of software bugs found in the sol library and time spent fixing them, it was a slow process to implement features within the library. Given that sol utilizes high-level variadic template functions and SFINAE compile-time calculations and method resolution techniques \cite{cppreference:SFINAE} to implement most of its features, sol causes most compilers to begin to exponentially increase the time taken to compile \cite{GitHub:ThePhD:sol2:issue:126, GitHub:ThePhD:sol2:issue:295, GitHub:ThePhD:sol2:compilation}. sol's inherent compilation growth caused compilation times for procsim to grow from under 10 minute for a clean build to over 40 minutes as more Lua wrapped functionality was added. More over, the use of templated and SFINAE mechanics caused compiler errors that were near impossible to decipher due to the raw amount of template instantiations present making small errors take massive amounts of time to decipher often resulting in a ``try it and see'' approach to fixing compiler errors. The work completed in \cref{sec:cross-platform:sec:cmake-flows} was started with the goal to try and appease these compiler constraints as reductions in objects to compile would reduce the over-all compiling times -- linking times were inconsequentially affected by sol's combinatorial explosion. In addition to changing how the software was built, as little information was placed into headers as possible when declaring Lua wrappers. This approach allowed for hiding implementations and forcing the compilers to reuse template instantiations as best as possible. However, the times were still unable to lowered below approximately 20 minutes for a clean build. ``ThePhD'' has since created a feature known as \cxxinline{simple_usertype<T>} which provides a runtime-binding mechanism that severely reduces code size and memory contention in most compilers \cite{GitHub:ThePhD:sol2:simple-usertype}. At the time, the \cxxinline{simple_usertype<T>} had significant performance penalties at runtime that have since been removed. The performance penalties of \cxxinline{simple_usertype<T>} were severe enough to impede use within the procsim library.

\subsection{Loss of pedagogical gains for high- versus low-level constructs}

As the features were developed, it became obvious that the ``high-level'' software approach produced a significant hiding of underlying hardware design -- an original concern this approach was meant to combat. In revisiting other tools such as CPU Sim \cite{Skrien2001}, we realized that instead of ``lifting the black box,'' the Lua configurations only shaved several layers off leaving a largely opaque sheet across the model. The model of side-effect-based compilation is extremely powerful and useful as a productivity tool, but it does not benefit students as it hides a lot of wiring details from students. The side-effect based approach to state machine definition provided a higher level approach than projects like \cite{Black2013} but also hid too much of the implementation details from students reducing their hands-on design experience. This ``high-level'' synthesis of a control unit causes students to ignore design considerations surrounding control signals or control unit algorithms. This is particularly evidenced by comparing the control unit for the URISC ISA in \cref{fig:mavaddat1988-urisc-control-unit} to the instruction definition from \cref{lst:lua:urisc-example-2} coupled with the implicit fetch-decode cycle for execution. While the control unit displayed by \cref{fig:mavaddat1988-urisc-control-unit} is not inherently complicated, but it provides a significant design challenge for students to implement it themselves. The procsim configuration does not have any of these signals included and implicitly provides most of them. We believed this to be a direct counter to the pedagogical \cref{req:pedagogical}. The ease of use and agility provided by procsim's configurations is very powerful but costs students learning opportunities. We believed there to be a dissection point between the Lua synthesis of control unit logic and \cite{Black2013}'s approach using a state table. Students require the ability to get their ``hands dirty'' and unfortunately procsim's configurations could not provide enough dirt \cite{Skrien2001,Garcia2009,Ackovska2014,Black2013}.

\begin{figure}[tp!]
    \centering
    \includegraphics[width=0.8\linewidth]{img/mavaddat1988-urisc-control-unit}
    \caption{Control unit for the 16-bit URISC architecture from \cite[p.~331]{Mavaddat1988}.}
    \label{fig:mavaddat1988-urisc-control-unit}
\end{figure}

\section{Analysis of Requirements}

procsim provided a powerful simulation framework design and a lot of extremely strong ideas on how to develop a proper cross-platform, high-performance solution to education of embedded systems and computer architectures. procsim  was proven to run on most major operating systems as required by \cref{req:personal} but required the installation of a program putting it a step behind a purely web-based application. The configurations available were not so deep as to provide complete circuit-level simulation like ShelbySim, CPU Sim or Emumaker86, but it intentionally left out mechanics to try and alleviate the overwhelming nature of a full-blown circuit simulation. Thus procsim met most of the configuration requirements for \cref{req:configuration}. In trading off configuration for pedagogy, procsim provided a solid base for improving students outcomes. But due to the level of information implicitly provided by the side-effect based execution, or outright hidden, it encroached and passed the requirement into becoming detrimental to pedagogy compared to competing projects (\cref{req:pedagogical}). 

Simulations within procsim were fast and provided hooks for all information within components. It did not however provide support for reading signals within the system or investigation of microcode execution. It had support for event-based execution implying different granularities of debugging could be implemented on top of the simulation engine. These features provide most of the requirements for \cref{req:simulations} but procsim had no capabilities for peripheral support at the time. The event-based execution engine would have allowed for granular debugging. Lastly, the IDE provided by the original hc12sim project was more modern than most projects surveyed, but it did not have the features required to keep up with major IDEs. It was our intention to integrate procsim into Eclipse and utilize the Lua Development Toolkit to provide the procsim simulator as an Eclipse-based IDE \cite{Eclipse:LDT}. This would make procsim extremely modern as a fully-featured IDE thanks to Eclipse's plugin architecture. Additionally, procsim utilized cutting edge technologies through Lua and C++11 / C++14 to produce powerful and easy to use software familiar to students. This modern tool set combined with a current IDE would create a modern feeling experience for students alleviating concerns of ``dated'' technologies for \cref{req:modern}.

\begin{table}[h!]
    \centering
    \begin{tabular}{l|cccccc}
        \textbf{Requirements} & \textbf{\hyperref[req:personal]{R1}} & \textbf{\hyperref[req:configuration]{R2}} & \textbf{\hyperref[req:pedagogical]{R3}} & \textbf{\hyperref[req:simulations]{R4}} & \textbf{\hyperref[req:modern]{R5}} & \textbf{Total} \\ \hline
        \textbf{\hyperref[ch:lua]{procsim}} & 
        4 & 3 & 3 & 3 & 4 & \textbf{17} \\
    \end{tabular}
    \caption{Summary of requirement matching for procsim.}
\end{table}