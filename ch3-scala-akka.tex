\chapter{procsim.scala, an Scala processor simulator for the modern Web}
\label{ch:akka-lua-configuration}

\newcommand{\scalainline}[1]{\mintinline{scala}{#1}}
\newcommand{\akkaActor}{\scalainline{Actor}}

\section{Introduction to Scala and Akka}

procsim.scala was a project to try and port work in the hc12sim tool to Scala and Akka\footnote{See \cref{sec:review-prev-hc12} for an extended discussion on the original hc12sim}. In recent years, Scala has emerged as a powerful language used in big data and scalable web applications thanks to Apache Spark \footnote{Apache Spark is available at: \url{https://spark.apache.org/}} and Lightbend Akka\footnote{Lightbend was formerly known as Typesafe. Akka is available at: \url{https://akka.io}} \cite{Karau2015, Alexandrov2014, Singh2015}. Scala is a multi-paradigm programming language supporting functional and object-oriented style programming on the Java Virtual Machine and in a JavaScript environment \cite{Scala-Lang}. One of Scala's original use-cases was as a scripting language on top of the Java Virtual Machine. Scala's implicit parameters \cite{Scala-ImplicitParameters}, custom operator overloading \cite{Scala-Operators} and optional post-fix notation \cite{Scala-MethodInvocations} allow developers to create Domain-Specific Languages with ease. For example, \cref{lst:scala-dsl-basic} show cases a DSL that was written to emulate BASIC (a 50 year-old language). The example is meant to be a proof-of-concept, showcasing the flexibility that Scala's syntax provides. In regards to processor simulation, all of the simulators surveyed provide at least one mechanism for loading and saving machine state to a persistent storage (e.g. XML files for \cite{Skrien2001, Black2013}). A DSL-based configuration allows specification of a system without extraneous syntax designed specifically for this purpose. Utilizing a DSL could allow students to specify their machines programmatically\todo{spelling?}{} rather than through a graphical user interface improving the amount of configuration, reuse and flexibility available. This provides an excellent approach to improving \cref{req:configuration} configuration requirements.\todo{But at what cost!?}

\begin{listing}[bt!]
    \begin{minted}{scala}
    object SquareRoot extends Baysick {
        def main(args:Array[String]) = {
            10 PRINT "Enter a number"
            20 INPUT 'n
            30 PRINT "Square root of " % "'n is " % SQRT('n)
            40 END
            
            RUN
        }
    }
    \end{minted}
    \caption{An example DSL source written in Scala to emulate BASIC called ``Baysick'' \cite{FogusBaysick}}
    \label{lst:scala-dsl-basic}
\end{listing}

Akka is a Scala framework that provides an implementation of the Actor model \cite{Agha1985} originally written by Haller and Odersky in \cite{Haller2009} for the Scala Library. \cite{Haller2009}'s original implementation makes use of an event and message-driven programming to lower thread counts and alleviate lock contentions compared to traditional threading models. \Cref{fig:doyle2014-akka-actor-model} shows a simple diagram of \akkaActor{} sending messages bi-directionally between each other. Each \akkaActor{} has a ``mailbox'' that they can store and process messages from. The initial actor implementation by \cite{Haller2009} was expanded to become Akka which is now sponsored by Lightbend. Akka's major revision to \cite{Haller2009}'s original work includes additional abstractions to add location transparency such that allow actors ``live'' wherever they are best suited  and scheduling mechanisms for controlling \akkaActor{} execution patterns in a deterministic way \cite{TypesafeAkka2015}. For example, two \akkaActor{} instances can communicate with each other regardless of their physical location on the same node of a distributed system or completely geographically separated by a network -- an individual actor neither knows nor cares where a message comes from or is sent to. Further, Akka provides fault tolerance through supervisor semantics utilizing the ``let-it-crash'' paradigm for faults popularized by the Erlang programming language in telecommunication systems since 1985 \cite{Armstrong2010}. These features on top of the actor model create a very scalable technology that maps simply to microservice-driven architectures. While Akka's main goal is to create microservice architectures and scalable applications, the author intended to utilize this model to instead implement an event-driven simulation model.

\begin{figure}[bh!]
    \centering
    \includegraphics[width=0.7\linewidth]{img/doyle2014-akka-actor-model}
    \caption{Graphical representation of three Actors sending bi-directional messages \cite{DoyleAkka2014}.}
    \label{fig:doyle2014-akka-actor-model}
\end{figure} 

\section{Event and Message-driven Simulation}

Several projects surveyed utilized event-driven models of simulation \cite{Nakamura2013, McLoughlin2010, Garcia2009}. As discussed in \cref{sec:review-summary}, event-driven models provide a simplification to maintenance of state within an application. In a traditional object-oriented application, each object maintains its own state performing create, read, update and delete operations on itself. In a traditional event-driven model, the ``owner'' of state still remains with components, however program flow is dictated by utilization of an event loop that processes events and asks components to ``react'' to these events further creating more events. This model is traditionally found in graphical user interface applications as it simplifies flow of a user-driven system. Lightbend coined the phrase ``reactive'' in regards to software by creating a manifesto known as the ``Reactive Manifesto'' that states the qualities of a ``reactive'' application \cite{ReactiveManifesto2014}. The ``Reactive Manifesto'' details message-driven applications as: 
\begin{displaycquote}{ReactiveManifesto2014}
    Reactive Systems rely on asynchronous message-passing to establish a boundary between components that ensures loose coupling, isolation and location transparency. This boundary also provides the means to delegate failures as messages. Employing explicit message-passing enables load management, elasticity, and flow control by shaping and monitoring the message queues in the system and applying back-pressure when necessary. Location transparent messaging as a means of communication makes it possible for the management of failure to work with the same constructs and semantics across a cluster or within a single host. Non-blocking communication allows recipients to only consume resources while active, leading to less system overhead.
\end{displaycquote}
While the majority of this definition deals with distributed systems, the same benefits are gained with local applications as well. A processor simulator does not require elasticity or load management; it does however require the ability to process messages quickly and in such a way that components do not block each other as electronics all operate in parallel. These ideals were transcribed into a model of a processor in which all components interact through ``signal'' messages between each other rather than direct interactions. This opens up the opportunity for much more accurate simulations while simultaneously reducing the effort to interact between components. These relationships would allow simulations to have higher fidelity and ease the time required to implement features lending well to both \cref{req:simulations,,req:pedagogical}. 

\section{Scala.js - Scala transpiler to JavaScript}

Scala.js is a compiler ``back-end'' for the Scala compiler that transpiles scala code to JavaScript so that it can run in a Web Browser. At the time of creating the procsim.scala project, the most recent release of the Scala.js transpiler was version 0.6.5 \cite{Scala-js2015}. Version 0.6.5 allowed for most Scala applications to be cross-compiled between Java Virtual Machine and JavaScript applications with little-to-no code changes. Through Scala.js, a simulation written in Scala could be run easily on both a desktop and web platform opening up the opportunity to utilize Scala for both a front-end client and a web service. \Cref{req:personal,,req:modern} support the use of a web-based solution due to the prevalence of web browsers compatibility in a cross-platform environment and current student's relative comfort with web-based applications. Given the author's strong Java and Scala background, utilizing Scala.js to build a fully-featured web application on top of the Scala and Akka platforms was an excellent candidate for this thesis project.

\section{Implementation of procsim.scala}

\subsection{VHDL-like DSL implementation and runtime-configured instructions}

The first goal of this project was to introduce a DSL for defining components and instructions within Scala. By creating a DSL that mimics VHSIC Hardware Descriptor Language (VHDL), a commonly used HDL language at \uwo{}, for students to define instructions within their processors. The intention was to have all components pre-built and configurable but instructions be specified by students to give a transparent look into microcoding on a processor. Given the compile-time configuration presented by the original hc12sim project in \cref{sec:hc12sim:instruction-generation}, it was our intention to allow students to have the same level of reconfigurability at runtime instead. The largest benefit to runtime configuration over compile-time removes the requirement to install a large compiler tool-chain and wait for the rest of a large application to compile which can take in the order of 10 to 40 minutes depending on the hardware utilized\footnote{On an Intel\textregistered{} i7-3770k, a clean build of the hc12sim project takes approximately 10 minutes, incremental builds were faster depending on the files modified.}. 

The author achieved runtime-configuration of a system by utilizing Scala's built-in reflection toolbox \cite{Scala-Reflection}. \textquote[\cite{Scala-Reflection}]{Reflection is the ability of a program to inspect, and possibly even modify itself.} Self modification of running code is the primary feature required for runtime configuration of a model without utilizing separate compiler tool-chains and processes. Scala's reflection tools allow for a developer to write code as a \mintinline{scala}{String} and execute the result, storing any and all state produced by the ``sub-program.'' This feature would allow students to specify code in a configuration editor interface and have the software provide Scala-based compilation feedback and JVM-level performance. Two listings are provided: \cref{lst:procsim-scala:concrete-instruction-def,,lst:procsim-scala:reify-instruction-def}, each shows the definition of the same simple instruction. The syntax used for assignment is meant to mimic the syntax used in VHDL to ``connect'' two components. \Cref{lst:procsim-scala:concrete-instruction-def} utilizes a normal Scala class to define these operations, but \cref{lst:procsim-scala:reify-instruction-def} uses runtime-reification to parse a \scalainline{String} and produce a result with the same functionality as \cref{lst:procsim-scala:concrete-instruction-def}. In small test benches, there is an initial overhead for parsing the \scalainline{String} and compiling it to run within the JVM at runtime, however there appears to be no performance penalty to execute code within a reified type. These test benches utilized primitive timing mechanisms and accounted for the JVM's JIT warm-up time. These use cases proved that it is possible to have completely runtime-based configuration within a Scala application. The examples shown have the ability to be expanded to mimic the capabilities found in simulators like TinyCSE \cite{Nakamura2013, McLoughlin2010}, reducing the overall knowledge required but still giving students the feeling of ``hands-on'' instruction modification meeting configuration \cref{req:configuration}.

\begin{listing}[ht!]
    \begin{minted}{scala}
    import net.navatwo._
    
    class Concrete extends Instruction {
        def exec(cpu: CPU) = {
            import cpu._
            A <= 5     // set A = 5
            B <= A + 1 // set B = A + 1 (6)
            A <= B     // set A = B
        }
    }
    val cIns = new Concrete
    \end{minted}
    \caption{Simple instruction that initializes values in registers defined through a Scala class definition.}
    \label{lst:procsim-scala:concrete-instruction-def}
\end{listing}

\begin{listing}[hb!]
    \begin{minted}{scala}
    import scala.reflect.runtime.{universe => u}
    val tb = mirror.mkToolBox()
    val tree = tb.parse("import net.navatwo._; " +
        "new Instruction { " +
            "def exec(cpu: CPU) = {" +
            "import cpu._;" +
                "A <= 5; " +
                "B <= A + 1;" +
                "A <= B;" +
            "}" +
        "}; ")
    val sIns = tb.eval(tree).asInstanceOf[Instruction]
    \end{minted}
    \caption{String-based reified instruction that mimics \cref{lst:procsim-scala:concrete-instruction-def}'s functionality.}
    \label{lst:procsim-scala:reify-instruction-def}
\end{listing}

\subsection{Akka-based Components}

The second challenge was utilizing the Akka framework to produce hardware configurations that were actor based. \begin{displaycquote}{Agha1985}
    A processor is a physical machine while a process is an abstract computation. From operating systems, we know that we may improve over-all performance of a processor by executing several processes concurrently instead of sequentially.
\end{displaycquote}
The previous quote is both ironic and informative. When considering hardware simulation, each component should be developed as an individual entity. Each has input and output connections and only cares about signals on input connections. Instead of considering the system sequentially, we consider the system as a massively parallel system in which all components processes signals concurrently. In Akka, all messages are passed to all components and it becomes a problem of filtering and producing data for other components. The author considered all hardware modules as \akkaActor{} instances and in doing so, all modules can process information ``concurrently'' within an Akka scheduler provided. Akka's schedulers may run sequentially or concurrently, it is decided by the scheduling algorithm but heavily suggests developers to treat everything as asynchronous to improve performance and reduce changes required should an \akkaActor{} move to a distributed environment later \cite{TypesafeAkka2015}. While there is no intention of ever moving a hardware simulation to multiple distributed nodes, the concepts of immutable messaging and decoupling mutability and behaviour into \akkaActor{} instances reduces the development choices in a positive way. 

Akka's \akkaActor{} works by sending messages between \akkaActor{} instances. In the context of Akka, a message is an envelope around state. Most often, this is a \mintinline{scala}{case class} in Scala. As stated previously, a message has only immutable state. In the context of hardware simulation, a clock pulse might be represented as a message shown in \cref{lst:procsim-scala:clock-pulse}. This message only contains the time that the message occurred, represented as a \javainline{Instant}\footnote{\javainline{Instant} is part of the \javainline{java.time} library: \url{https://docs.oracle.com/javase/8/docs/api/java/time/Instant.html}}. In order for another module to listen for this pulse, it must implement the \scalainline{Actor.receive} method which is a \scalainline{PartialFunction[Any, Unit]}. The \scalainline{def receive} method is usually implemented as a \scalainline{PartialFunction[]} using pattern matching \cite{Scala-PatternMatching} on message classes like \cref{lst:procsim-scala:clock-pulse}. \Cref{lst:procsim-scala:clock-pulse-actor} shows a \akkaActor{} that listens for our previously defined \scalainline{ClockPulse} message. In order to send a message to an \akkaActor{}, once an \akkaActor{} is created the \scalainline{!} operator sends the message: \scalainline{actor ! ClockPulse(Instant.now())}. The simplicity of these interactions allowed for very straight-forward communication protocols between modules and the paradigms enforced by Akka eased development efforts for new modules.

\begin{listing}
    \mint{Scala}|case class ClockPulse(time: Instant)|
    \caption{Clock pulse message for Akka}
    \label{lst:procsim-scala:clock-pulse}
\end{listing}

\begin{listing}
    \begin{minted}{scala}
    class ClockedActor extends Actor {
        override def receive = {
            case ClockPulse(time) => 
                println(s"Pulsed at $time")
            
            case _ => // do nothing
        }
    }
    \end{minted}
    \caption{\akkaActor{} that listens for \scalainline{ClockPulse} messages and prints the time.}
    \label{lst:procsim-scala:clock-pulse-actor}
\end{listing}


\section{Technology Failure}

This project progressed well while utilizing Akka on a local machine. However, in order to utilize Akka in the browser, much of Akka needed to be rewritten to utilize the browser concurrency semantics. For example, web browsers do not provide threading in the traditional sense, but do provide threading through Web Workers \cite{MDNWebWorkers}. Web Workers are not compatible with JVM threading as it is impossible with current technology to accomplish tasks such as shared memory or sleeping threads \cite{Doeraene2017}. Thus Scala.js has no means to implement Java's threading models natively. Without a supported JVM threading library, Scala.js does not have the ability to compile Akka to run within the browser. Conversely JavaScript's programming model is heavily focused on asynchronous single-threaded programming paradigm through callbacks and surprisingly its model lends well to the actor model from \cite{Agha1985}. As \cite{Doeraene2014} eloquently explains:
\begin{displaycquote}{Doeraene2014}
    It may seem contradictory to implement an actor model, which is inherently concurrent and asynchronous,
    on a purely single-threaded platform like Scala.js. However, concurrency and asynchrony must not be confused with parallelism. While parallelism involves physically executing different tasks at the same time, e.g., on multiple processors or multiple machines, concurrency is a form of modularity which allows to model software components as independent units of execution and behavior which can communicate between each other.
\end{displaycquote}
\cite{Doeraene2014} implemented Scala Actors on top of the JavaScript VM utilizing a single-threaded ``asynchronous model.'' \cite{Doeraene2014} was an Undergraduate project that porting the original Scala actors to run on a JavaScript VM. Through further development, \cite{Doeraene2014} was extended to implement the Akka interfaces and became what is now known as Akka.js \cite{Stivan2015, akka-js2015}. The Akka.js project implements nearly all of the features of Akka within a web browser environment. The project has grown quickly over time, but at the time of this authors work it had large bugs that this author was required to patch to utilize in a proper JavaScript program stack. These complications created massive work flow problems and a majority of time was spent debugging Akka.js rather than working on the procsim.scala project itself.

In addition to the immaturity, Akka could not keep up with simulation requirements (\cref{req:simulations}) as it did not support small discrete times. This author could only get messages to pass with approximately 50ms of latency between the sender and receiver. This was not acceptable in the concurrent environment that was expected at the time. 

Another fault of ecosystem immaturity was that Scala.js created applications that were too heavy-weight by default. At the time, the Scala.js compiler did not perform dead code elimination to an acceptable level leaving large applications to be distributed from a web server\footnote{As of July 2017, the Scala.js compiler has \textit{significantly} improved since the procsim.scala project and contains a powerful optimization tool-chain on top of Google's Closure Compiler \cite{Scala-js:CompOptPipeline}}.This meant that even small applications were in the order of mebibytes of data to serve as JavaScript sources from a web server. This size was unacceptable from an application distribution and usage stance (not adequately meeting \cref{req:personal}). 

\section{Fate of procsim.scala}\todo{Better title..}

Unfortunately, due to the immaturity of Scala.js, Akka.js and the ecosystem at the time, the procsim.scala project was ultimately discarded. The procsim.scala project had two strong points that should be addressed by future projects. First, using an ``always asynchronous'' approach to modelling components was very simple to reason about and eased implementation details significantly. However, the counter to that was that having all components be ``connected'' it meant that communication changed from a problem of ``where to send data?'' to a problem of ``which data does each component care about?'' This filtering was non-trivial and often meant that \akkaActor{} instances were spending more time filtering messages than actions. This author believes the question of ``which'' provides a simpler model than the direct connection model with the same power and was a good idea to investigate in future projects. The second strong point is using a runtime DSL to configure the system gives students the ability to modify components behaviour similar to the hc12sim's instruction generation scheme. The massive benefit over the previous project was in the runtime capabilities instead of compile-time reducing the cognitive load providing a foundation for both \cref{req:pedagogical,,req:configuration}. Additionally, a qualification that was found for such a DSL is that it must feel familiar to students so that they do not need to learn something entirely new (in the case of procsim.scala, this was using a VHDL-like syntax). 

\todo{Should code samples be included in appendix?}