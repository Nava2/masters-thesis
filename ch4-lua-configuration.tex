\chapter{Building a Lua-based configuration-driven processor simulation}
\label{ch:lua-config}

\newcommand{\cmakeinline}[1]{\mintinline{CMake}{#1}}
    
After concluding work on procsim.scala (\cref{ch:scala-akka}), this author considered taking the lessons learned from the Scala project and attempted to apply them to the original hc12sim project \cite{Brightwell2013}. Unfortunately, the hc12sim simulator was dated, poorly designed and poorly organized due to inexperienced student work. A large portion of effort was placed in modernizing and correcting the hc12sim software to be well tested, build in a cross-platform environment and ease development and maintenance. Following these improvements, the software was renamed procsim as it was intended to be a general purpose simulation framework rather than tied to the \hcmodel{}. From working with Scala-based configurations in \cref{sec:sec:procsim-scala:configuration}, the author believed that runtime-configuration was extremely important in defining processors for students. The author chose to expand the hc12sim project and replace the JSON-based, compile-time configuration capabilities with runtime-based configurations utilizing an embedded scripting language. Within the C++ programming ecosystem, there exists many different scripting environments that can be embedded with varying degrees of difficulty, feature capabilities and execution speeds. The author investigated utilization of several scripting environments before settling on utilizing Lua \cite{LuaHomepage} with bindings provided through sol2, a wrapper between C++ and Lua API calls \cite{Solv2.11.7}. Once Lua was selected, the author designed configuration schemas built to execute in a Lua sandbox with timing and other hardware-level considerations abstracted away from the configuration definitions as much as possible.

\section{Creating procsim: Modernizing hc12sim}

The hc12sim project that was showcased in \cite{Brightwell2013} was written to be modern at the time. Since 2013, the C++ community has progressed thoroughly and many of the libraries in use within the project were discontinued or lost support. The hc12sim project utilized many poor practices such as excessive use of \cxxinline{typedef} statements making it very difficult to reason what parts were. Additionally, the project heavily relied on Boost's non-standard implementations of \verb|tr1| structures such as \cxxinline{boost::shared_ptr<T>} \cite{Boost1.53.0:SmartPointers} (now superseded by \cxxinline{std::shared_ptr<T>} \cite{cppreference:shared-ptr}) and the C++11 threading in Boost \cite{Boost1.53.0:Thread} (superseded by \cxxinline{<thread>} \cite{cppreference:thread}). The insidious nature of threading libraries and smart pointer usage made this effort an unfortunately large task. Additionally, when writing C++ software distribution of binary files is a common concern when working in cross-platform environments. Thus, a concious effort was made to remove all binary-based libraries in favour of header-only library usage which remove most concerns of distributing incompatible binaries.


\subsection{Cross-platform development}
\label{sec:lua:sec:cross-platform-development}

The C++ language has unofficially always tried to meet the motto: ``write once, compile anywhere.'' With any compiled language, when moving between platforms it can be non-trivial to assure that compiled code will run between any two platforms. Given that \cref{req:personal} requires that any such solution must run within personal computers, the author was required to have the procsim project run on the three major platforms, Microsoft Windows, macOS and GNU/Linux. Within the C++ ecosystem, the most assured way to complete this is to try and utilize only commonly used tools and try to utilize the Standard Template Library (STL) as much as possible. That is not to say there are not powerful cross platform libraries (e.g. Qt \cite{Qt}, Boost \cite{Boost}), these libraries provide excellent tools but often introduce complex build requirements and add large binary files into any distributed application. An artefact of 2013, Microsoft's Visual C++ (MSVC) 2011 compiler and accompanying STL were not completely standards compliant with C++11 and thus \cite{Brightwell2013} required the use of Boost \cite{Microsoft:MSVC:ModernCPP:2011}. Many of the C++11 STL additions were modelled after Boost's implementations \cite{Meyers2005}. In 2015, the Boost's STL implementation dependency was removed by upgrading the lowest supported compiler to MSVC 2015 which fully supports C++11 in both compiler semantics and STL compatibility \cite{Microsoft:MSVC:ModernCPP}. This allowed the author to fully remove the main Boost dependencies on Boost.Memory and Boost.Thread. By removing these library dependencies, it eased cross-platform development as only the Boost C++ headers were required to compile the procsim project. However, the unit test platform for hc12sim was based on Boost.Test \cite{Boost1.53.0:Test} -- a problem addressed later.

\subsubsection{Access to multiple platforms}

Once the procsim project utilized the C++11 standard STL over Boost the next task was configuring mechanisms to ensure platforms performed correctly. It was found multiple times that different compiler's STLs behaved differently depending on different versions. For example, the author found that the GNU Compiler Collection (GCC) \cite{GCC} 5.X C++ STL shipped with a broken version of the C++11 \cxxinline{<regex>} library. This bug was found late because testing on macOS's Xcode 8.3 and MSVC 2015 passed (the authors two main platforms). However, on a ``whim'' building on Linux was tested and the issue was found -- unit tests checked this functionality. This small issue opened up a question: How can the software be verified working on three major platforms while not having native access to each platform? The approach at the time was to change computers to access the different major operating systems. It became difficult to maintain what changes were made over time to have the project build properly. This meant that sharing the software development environment became difficult and near impossible to replicate at times. In previous works, the author had utilized VMWare vSphere \cite{VMWare:vSphere} technologies to create common developer ``environments'' through Virtual Machines that could be consistently used for development and testing. 

Given that vSphere is a proprietary and expensive software, the author researched other tools that provided virtualized environments. Oracle's VirtualBox \cite{Oracle:VirtualBox} provides virtual machine provisioning through open source tools. Building on the idea of ``cloning'' common configurations between development environments through VirtualBox, the author eventually found HashiCorp's Vagrant \cite{VagrantUp}. Vagrant provides a consistent declarative interface for defining a virtual machines configuration through Ruby scripts. Vagrant's parent company, Hashicorp, hosts ``boxes'' that are preconfigured virtual machines ranging from Ubuntu Linux to FreeBSD to macOS El Capitain \cite{Vagrant:Boxes}. These ``base'' boxes are then configured to match the environment requirements for a project. For example, \cref{lst:lua:ubuntu-vagrant-box} show cases a simple configuration that installs both GCC 5.X and Low-Level Virtual Machine (LLVM) Clang \cite{LLVM:Clang} 3.7 -- two fully C++11 compliant compiler tool-chains. These configurations are known as ``Vagrantfiles'' and are full Ruby programs, implying they can utilize Ruby's full ecosystem of software. The author used Vagrant and VirtualBox to create three environments for Microsoft Windows 10, macOS El Capitain, Ubuntu 14.04 Precise and Ubuntu 16.04 Xenial. These configurations allowed instantiating virtual machines quickly and consistently on any platform to build and run test configurations. With the three platforms easily accessible, it became necessary to improve the build infrastructure to be consistent across these platforms.

\begin{listing}[tp]
\begin{minted}[breaklines=true]{Ruby}
Vagrant.configure("2") do |config|
    # Utilize the ubuntu/trusty64 box to give a 14.04 environment
    config.vm.box = "ubuntu/trusty64"
    
    config.vm.provider "virtualbox" do |vb|
        vb.cpus = 2
        vb.memory = 2048
    end
    
    # Install/update prerequisite software:
    config.vm.provision "shell", privileged: true, inline: <<-EOF
        echo "Installing build prequisisites: git, compiler ppas"
        apt-get install -q -y git 
        # Compiler tool-chains
        apt-add-repository -y ppa:ubuntu-toolchain-r/test 
        apt-add-repository -y ppa:adrozdoff/llvm-backport 
        apt-get update -qq
    EOF
    
    config.vm.provision "shell", privileged: true, inline: <<-EOF
        echo "Installing build compiler toolchains"
        apt-get install -q -y clang-3.7 \
                              gcc-5 g++-5 \
                              --force-yes
    EOF
    
    # Update all existing packages last
    config.vm.provision "shell", privileged: true, inline: "apt-get dist-upgrade -y ; apt-get autoremove --purge -y"
end # end vagrant file 
\end{minted}
\caption{Vagrant file that describes a Ubuntu 14.04 box with modern GCC 5.X and LLVM Clang 3.7 compilers installed.}
\label{lst:lua:ubuntu-vagrant-box}
\end{listing} 

\subsubsection{Building with cross-platform tools}

CMake \cite{Kitware:CMake} is a cross-platform meta-build system. A meta-build system provides a ``front-end'' language for defining a project's build and then generates a build program for other build systems to consume. CMake provides support for many different build systems, each is supported through a CMake ``generator''. The generators required to build on the Windows, macOS and Linux were ``Unix Makefiles'' for GNU \verb|make| \cite{GNU:Make} on Linux and macOS, ``Xcode'' for macOS's IDE Xcode \cite{Apple:Xcode}, and ``Visual Studio 14 2015 [Win64]'' for MSVC 2015 \cite{CMake:Generators}. On Unix environments, \verb|make| is generally available however and a newer build tool, \verb|ninja| \cite{NinjaBuild}, is preferred as builds are faster and provides the same familiar behaviours as \verb|make|. As stated, CMake provides a cross-platform meta-build system, however this meant writing cross-platform build scripts for the procsim project. In the original hc12sim project \cite{Brightwell2013}, CMake was utilized however it was poorly organized and added large coupling file dependencies. For example, changing a single file caused the entire build to trigger rather than just dependencies. At first, this was thought to be caused by CMake not properly structuring file dependencies, however it was soon found to be due to poor header isolation and deep, nested coupling. The author separated all headers to try and isolate concerns of what a header ``does'' and remove inter-dependencies as much as possible. Reorganization of the procsim library coupled with improved build tools and the addition of OBJECT library files \cite{CMake:add_library:ObjectLibraries} significantly reduced build time and allowed for less time spent compiling the procsim project. 

As previously discussed, compilers come with consequential differences in support for new and current standards. In order to try and utilize features appropriately it is often helpful to ``test'' compilers support of features. CMake provides this functionality through cmake-compiler-features \cite{CMake:compile-features} but CMake's built-in support lags heavily behind current C++ standards (including C++14 and 17 at the time of writing). Fortunately, compatibility \cite{CMakeCompatibility} is a library used to enhance compiler and STL feature detection. The author worked with M\"uller to improve compatibility features and generation of header files that will include a ``shim'' on top of the current STL to add features where possible. ``Shims'' can only be added for STL features as syntax elements are not extensible in C++. The use of compatibility allows the procsim project to build more easily on the three major platforms. 

\subsection{Testing Infrastructure}

Testing a multi-platform compiled project is very difficult and relies on many tools to be successful. Through utilization of Vagrant and better build infrastructure within CMake scripts, the procsim project was able to be automatically tested on multiple platforms through continuous integration software. Continuous integration describes a process of building, testing and deploying software as rapidly as possible to reduce time-to-market for software projects \cite{Stolberg2009}. Idealistically, by utilizing continuous integration, developers receive near-instantaneous feedback on whether or not a particular change set breaks the product in unforeseen ways -- this heavily depends on the level of testing and environments available. For procsim, the author configured a small ``micro-PC'' with an Intel \textregistered{} i5-4590T and 4 GB of RAM to run a Jenkins \cite{Jenkins:Home} continuous integration server. 

Within Jenkins, Vagrant was used to create virtual machines that acted as ``slaves'' to the ``master'' Jenkins service utilizing Jenkins' distributed build infrastructure \cite{Jenkins:DistributedBuilds}. Each of these virtual machines was spawned to utilize a separate configuration to test the procsim project against. For example, one machine spawned a Ubuntu 14.04 machine with manually installed compiler tool-chains and a second machine spawned a macOS instance with Xcode 8. Each machine ran the exact same unit tests after configuration of the virtual machine and selection of a CMake generator. This was achieved utilizing a Jenkins Pipeline \cite{Jenkins:Pipeline} specified in a Jenkinsfile script \cite{Jenkins:Pipeline:Jenkinsfile}. Jenkins Pipelines allow for parallel execution of ``tasks,'' dependent and independent, for a continuous integration task graph. For the procsim project, due to its immaturity, the pipeline only included stages for building the software and running unit tests within the multiple operating system platforms required by \cref{req:personal}. While not strictly related to simulation \cref{req:simulations}, the addition of a continuous integration solution allowed the author to maintain a rapid pace of development and provide confidence that changes made worked across all platforms.  

Over the course of the procsim project, the build process became more and more complicated requiring improvements in automating the build process. When writing unit tests, the original hc12sim project utilized Boost.Test \cite{Boost1.53.0:Test} for creating and running unit tests. Unfortunately, Boost.Test required library distribution which made working on platforms without software distribution systems difficult (e.g. Windows or macOS). In order to remove the final thread of Boost binary dependence, the author replaced Boost.Test with Catch \cite{CatchLib}. Catch is a header-only C++ testing framework built on top of modern C++. The single-header configuration removed the final binary dependency. Catch provides a Behaviour-Driven Development (BDD) interface that allows developers to describe the behaviour of their system within their tests creating easily understandable and clearly organized tests \cite{Solis2011}. Catch improved the mechanisms used to test and provided an easier to maintain testing suite. Catch's test runner requires that all tests are defined through C-style macros and the executable must include Catch's main through \verb|main| the \cxxinline{CATCH_CONFIG_MAIN} macro \cite{CatchLib:Tutorial}. When defining many tests, it is often useful to organize them in meaningful ``suites'' of test executables. With any testing framework, when creating multiple executables it is advantageous to share object resources to reduce compiling time -- particularly in \cxxinline{template} or \cxxinline{constexpr} heavy software.

\subsection{Improving developer work flows within CMake}

In \cref{sec:lua:sec:cross-platform-development}, CMake was discussed as the build tool for the procsim project. CMake utilizes \cmakeinline{OBJECT} libraries to allow multiple ``targets'' to share compiled object files and statically link against the same objects as required. These \cmakeinline{OBJECT} libraries are not the same as shared objects or DLLs and should not be treated as the same. An \cmakeinline{OBJECT} library is a CMake abstraction on top of compiled compilation units that must be statically linked into some other object. These shared \cmakeinline{OBJECT} libraries were very useful in unit test files as a common object used between each executable ``suite'' is the \verb|main| test runner. Manually specifying all of these suite instances to get individual suites and manually maintain a global ``test all'' suite was frustrating. The author developed a series of CMake macros \cite{CMake:macro} and functions \cite{CMake:function} to reduce the required commands to define tests and library files. \Cref{lst:lua:cmake-test-declaration} shows a simple shared library defined utilizing the build infrastructure described. Three functions are used to define four distinct targets: 
\begin{enumerate}
    \item \cmakeinline{new_project()} defines a ``project'' of sources which could be an executable, shared/static library, etc.
    \item A library, \verb|procsim| with headers, sources and external dependencies;
    \item Two test suites that test ``packages'' of code in the library from (1) and depend on it and a common test-harness;
    \item An aggregate \cmakeinline{PROJECT} suite that combines all the tests from each suite into the current project
\end{enumerate}
Within these functions, each performs many tasks to try and simplify definition of parts of a completed program.

\begin{listing}[hp]
\begin{minted}{CMake}
new_project()

# Define a new library called ``procsim''
new_library(procsim 
    HEADERS procsim/encoding/Algorithm.hpp
            procsim/encoding/Code.hpp
            procsim/encoding/Operand.hpp
            procsim/encoding/Primitives.hpp
            procsim/encoding/Utility.hpp
            
            procsim/time/Clock.hpp
            procsim/time/Timer.hpp
            procsim/time/AsyncTimerReceiver.hpp
    
    SOURCES encoding/Algorithm.cpp
            encoding/Code.cpp
            encoding/Operand.cpp
            encoding/Primitives.cpp
    
            time/Clock.cpp
            time/Timer.cpp
            time/AsyncTimerReceiver.cpp
    
    GENERATED_HEADERS ${PROCSIM_EXPORT_HEADER}
                      ${PROCSIM_COMPILER_HEADER}
    VENDORS cpp17_libs fmtlib                      # non-builtin
    INCLUDE_DIRECTORIES ${Boost_INCLUDE_DIRS}
    LIBS                ${CMAKE_THREAD_LIBS_INIT}) # builtin libs

# Create two test suites utilizing the new library      
create_test(time     SOURCES time/ClockTest.cpp 
                             time/TimerTests.cpp
                     LIBS    procsim test-harness)
                     
create_test(encoding SOURCES encoding/CodeTest.cpp
                             encoding/OperandTest.cpp
                             encoding/PrimitivesTest.cpp
                             encoding/UtilityTest.cpp
                     LIBS    procsim test-harness)
# Create a test for the whole project
create_test(core     PROJECT)
\end{minted}
\caption{CMake script showing how two test suites, \cmakeinline{time} and \cmakeinline{encoding}, are defined as part of a project, \cmakeinline{core}}
\label{lst:lua:cmake-test-declaration}
\end{listing}
 
The function, \cmakeinline{new_project()} defines a set of many ``global'' variables within the build that are named after the directory that the current defined CMake script is found. For example, if \cref{lst:lua:cmake-test-declaration} was found in ``procsim/core'' the project would be called ``core.'' This behaviour is meant to be consistent and simplistic. The model is based on the idea of ``convention over configuration'' which was popularized by tools and frameworks like Apache Maven \cite{Maven:StandardDirectoryLayout} and Ruby on Rails \cite{Heinemeier:RailsDoctrine}. The function defines the following global state (truncated for brevity): 
\begin{itemize}
    \item \cmakeinline{SOURCE_DIR}: Implementation files
    \item \cmakeinline{INCLUDE_DIR}: Header files
    \item \cmakeinline{TEST_DIR}: Test implementations
\end{itemize}
These properties are used to generate ``namespaced'' build targets and variables allowing for use in specification within CMake's dependency graph. To simplify, if you define two projects, \verb|a| and \verb|b|, you can set \verb|b| to depend on \verb|a| being built first. Once the \cmakeinline{new_library()} function is called within a cmake script hierarchy, all further functions from the build tools will utilize the state set by the project. 

The function \cmakeinline{new_library()} creates a new library target that compiles all of the specified files to create a library. The function accepts \cmakeinline{OBJECT}, \cmakeinline{INTERFACE}, etc. to match \cite{CMake:add_library} trying to remove any discontinuity between the two functions. As shown in \cref{lst:lua:cmake-test-declaration}, there are several other parameters used: 
\begin{description}
    \item[HEADERS] Header files
    \item[SOURCES] Implementation files
    \item[GENERATED\_SOURCES] Source files that are generated at build time by another target
    \item[GENERATED\_HEADERS] Same as \verb|GENERATED_SOURCES| except Headers
    \item[VENDORS] These are external dependencies that are built within the build chain after downloading from an external source. This forces the library to depend on their download and build
    \item[LIBS] These are internal CMake libraries or other targets that are built in a multi-project configuration
\end{description}
Utilizing these arguments, the function creates appropriate CMake targets and adds the required dependencies to the new library target. In addition, it performs platform-specific compiler adjustments to try and reduce the amount of configurations required per target. For example, many flags for MSVC to not apply to Clang which do not apply to GCC. This torrent of compiler option configuration is eased by the use of CMake's generator expressions \cite{CMake:generator-expressions} but many compilers do not properly identify with CMake's infrastructure so manual adjustments must be made to modernize these facilities. Further, by utilizing our own mechanism, the targets created have ``localised'' include directories that do not pollute other targets. If two targets require different versions of the same files, the built-in \cmakeinline{include_directories()} command will cause these targets to ``collide'' and fail to compile \cite{CMake:include-directories}. Further, the \cmakeinline{new_library()} appropriately applies the \cmakeinline{SYSTEM} option to all includes that are outside of the whole multi-project build so any warnings generated are not applied. Lastly, \cmakeinline{install} targets are created that will install headers and compiled binaries to appropriate locations depending on the type of library and the platform in use (Microsoft Windows requires libraries be beside their executables, where UNIX utilizes PATH resolution mechanics).

The last function used in \cref{lst:lua:cmake-test-declaration} is \cmakeinline{create_test()} which has three distinct incantations. The first creates a single test suite from Catch-based test sources (\cite{CatchLib}). These sources are aggregated and compiled to an \cmakeinline{OBJECT} library. This library is concatenated to the current \cmakeinline{PROJECT}'s test executable. By generating \cmakeinline{OBJECT} libraries, these smaller units of compilation can be combined and reused intelligently saving large amounts of compile time as previously discussed. The second use of \cmakeinline{create_test(test PROJECT)} generates a \cmakeinline{PROJECT}-based test executable and ``check'' target that runs the executable. This test executable includes all previously defined \cmakeinline{OBJECT} libraries in the current ``project.'' This executable is used to debug and execute tests for the given project, it is currently not possible to run a smaller test individually. Additionally, the generated executable is registered with CMake's CTest which creates build-script targets to run test executables providing dashboards and other useful tools \cite{CMake:CTest}. The last use case is \cmakeinline{create_test(target ALL)}. The \cmakeinline{ALL} request generates a test executable that includes every test suite created in a multi-project build into a single executable -- a convenience executable. As multi-project programs develop, it is useful to be more and less granular depending on the context at the time of use. While intuitively it appears as though large amounts of executables create large amounts of compilation units creating a very slow build time, due to the use of \cmakeinline{OBJECT} libraries created at definition, adding more test executables only adds incremental link time due to linking static objects -- a marginal increase of time for the convenience provided. The full test output from the procsim project is shown in \cref{lst:lua:ctest-output}. The output is easy to read and should errors occur, catch provides assertion errors and suites will continue summarizing errors later.

\begin{listing}[hb]
\begin{verbatim}
1>--- Build started: Project: RUN_TESTS, Configuration: Debug x64 ---
1>  Test project S:/research/procsim/build-windows
1>        Start  1: core-components
1>   1/11 Test  #1: core-components ............   Passed    0.09 sec
1>        Start  2: core-encoding
1>   2/11 Test  #2: core-encoding ..............   Passed    0.06 sec
1>        Start  3: core-time
1>   3/11 Test  #3: core-time ..................   Passed    4.46 sec
1>        Start  4: core-misc
1>   4/11 Test  #4: core-misc ..................   Passed    0.09 sec
1>        Start  5: conf-encoding
1>   5/11 Test  #5: conf-encoding ..............   Passed    0.20 sec
1>        Start  6: conf-loader
1>   6/11 Test  #6: conf-loader ................   Passed    0.06 sec
1>        Start  7: conf-arch
1>   7/11 Test  #7: conf-arch ..................   Passed    0.07 sec
1>        Start  8: conf-components
1>   8/11 Test  #8: conf-components ............   Passed    0.13 sec
1>        Start  9: conf-proc
1>   9/11 Test  #9: conf-proc ..................   Passed    0.18 sec
1>        Start 10: conf-time
1>  10/11 Test #10: conf-time ..................   Passed    0.07 sec
1>        Start 11: conf-env
1>  11/11 Test #11: conf-env ...................   Passed    0.04 sec
1>
1>  100% tests passed, 0 tests failed out of 11
1>
1>  Total Test time (real) =   5.50 sec
======= Build: 1 succeeded, 0 failed, 1 up-to-date, 0 skipped =======
\end{verbatim}
\caption{Test output from CTest \cite{CMake:CTest} from Microsoft Visual Studio Community 2015 for the procsim project.}
\label{lst:lua:ctest-output}
\end{listing}  

All of these build improvements worked towards improving software maintainability of the simulation suite. Whilst these changes do not directly contribute to the \cref{sec:problem-statement}, it is patent that improvements in developer work flow have a direct consequence in improvements to developer time resources and reduces the likelihood of poor software being produced. Given improvements to developer productivity, one may argue simply that this improves the validity of producing modern software (\cref{req:modern}) and any software produced will more accurately meet requirements specified. As such, these improvements allowed this author to develop the procsim project more rapidly and reduced time spent fighting against compilers and cross-platform development issues.


\section{Utilizing runtime configurations through scripting}

procsim.scala had a VHDL-like


\subsection{Scripting language selection}
\lipsum[1]

% JavaScript via V8, Python via Boost.Python, SWIG and .. well anything, Lua + Luacppinterface/sol/sol2



\subsection{Configuration versus Simulation entities}

The original hc12sim project shared all components between both configuration and simulation. This meant less lines of code to understand and generally made the software ``easier'' to write. However, as modules grow in size, they become more complicated to maintain. Something found in work for \cref{ch:scala-akka} was that immutable objects produce easier to reason and better performing software.


\subsection{Lua integration}
\lipsum[1]

\section{Lua-based Configuration}

\lipsum[1]

\begin{listing}[hp!]
    \inputminted{lua}{./listings/x86_example.1.lua}
    \caption{Sample configuration showcasing a simple x86-like processor}
    \label{lst:lua:x86-example-1}
\end{listing}

\begin{listing*}[hp!]
    \inputminted[firstnumber=last]{lua}{./listings/x86_example.2.lua}
    \caption{(Continued) Sample configuration showcasing a simple x86-like processor}
    \label{lst:lua:x86-example-2}
\end{listing*}

\begin{listing*}[hp!]
    \inputminted[firstnumber=last]{lua}{./listings/x86_example.3.lua}
    \caption{(Continued) Sample configuration showcasing a simple x86-like processor}
    \label{lst:lua:x86-example-3}
\end{listing*}

\lipsum[2-4]

\section{Side-effect-based execution}
\lipsum[1]

\section{Technology challenges}
\lipsum[1]

\section{``Lessons learned''}
\lipsum[1]
