\chapter{procsim: A Lua-based configuration-driven processor simulator}
\label{ch:lua-config}
    
After concluding work on procsim.scala (\cref{ch:scala-akka}), this author considered taking the lessons learned from the Scala project and attempted to apply them to the original hc12sim project \cite{Brightwell2013}. Unfortunately, the hc12sim simulator was dated, poorly designed and poorly organized due to inexperienced student work. A large portion of effort was placed in modernizing and correcting the hc12sim software to be well tested, build in a cross-platform environment and ease development and maintenance. Following these improvements, the software was renamed procsim as it was intended to be a general purpose simulation framework rather than tied to the \hcmodel{}. From working with Scala-based configurations in \cref{sec:sec:procsim-scala:configuration}, the author believed that runtime-configuration was extremely important in defining processors for students. The author chose to expand the hc12sim project and replace the JSON-based, compile-time configuration capabilities with runtime-based configurations utilizing an embedded scripting language. Within the C++ programming ecosystem, there exists many different scripting environments that can be embedded with varying degrees of difficulty, feature capabilities and execution speeds. The author investigated utilization of several scripting environments before settling on utilizing Lua \cite{LuaHomepage} with bindings provided through sol2, a wrapper between C++ and Lua API calls \cite{Solv2.11.7}. Once Lua was selected, the author designed configuration schemas built to execute in a Lua sandbox with timing and other hardware-level considerations abstracted away from the configuration definitions as much as possible.

\section{Creating procsim: Modernizing hc12sim}

The hc12sim project that was showcased in \cite{Brightwell2013} was written to be modern at the time. Since 2013, the C++ community has progressed thoroughly and many of the libraries in use within the project were discontinued or lost support. The hc12sim project utilized many poor practices such as excessive use of \cxxinline{typedef} statements making it very difficult to reason what parts were. Additionally, the project heavily relied on Boost's non-standard implementations of \verb|tr1| structures such as \cxxinline{boost::shared_ptr<T>} \cite{Boost1.53.0:SmartPointers} (now superseded by \cxxinline{std::shared_ptr<T>} \cite{cppreference:shared-ptr}) and the C++11 threading in Boost \cite{Boost1.53.0:Thread} (superseded by \cxxinline{<thread>} \cite{cppreference:thread}). The insidious nature of threading libraries and smart pointer usage made this effort an unfortunately large task. Additionally, when writing C++ software distribution of binary files is a common concern when working in cross-platform environments. Thus, a concious effort was made to remove all binary-based libraries in favour of header-only library usage which remove most concerns of distributing incompatible binaries.


\subsection{Cross-platform development}
\label{sec:lua:sec:cross-platform-development}

The C++ language has unofficially always tried to meet the motto: ``write once, compile anywhere.'' With any compiled language, when moving between platforms it can be non-trivial to assure that compiled code will run between any two platforms. Given that \cref{req:personal} requires that any such solution must run within personal computers, the author was required to have the procsim project run on the three major platforms, Microsoft Windows, macOS and GNU/Linux. Within the C++ ecosystem, the most assured way to complete this is to try and utilize only commonly used tools and try to utilize the Standard Template Library (STL) as much as possible. That is not to say there are not powerful cross platform libraries (e.g. Qt \cite{Qt}, Boost \cite{Boost}), these libraries provide excellent tools but often introduce complex build requirements and add large binary files into any distributed application. An artefact of 2013, Microsoft's Visual C++ (MSVC) 2011 compiler and accompanying STL were not completely standards compliant with C++11 and thus \cite{Brightwell2013} required the use of Boost \cite{Microsoft:MSVC:ModernCPP:2011}. Many of the C++11 STL additions were modelled after Boost's implementations \cite{Meyers2005}. In 2015, the Boost's STL implementation dependency was removed by upgrading the lowest supported compiler to MSVC 2015 which fully supports C++11 in both compiler semantics and STL compatibility \cite{Microsoft:MSVC:ModernCPP}. This allowed the author to fully remove the main Boost dependencies on Boost.Memory and Boost.Thread. By removing these library dependencies, it eased cross-platform development as only the Boost C++ headers were required to compile the procsim project. However, the unit test platform for hc12sim was based on Boost.Test \cite{Boost1.53.0:Test} -- a problem addressed later.

Once the procsim project utilized the C++11 standard STL over Boost the next task was configuring mechanisms to ensure platforms performed correctly. It was found multiple times that different compiler's STLs behaved differently depending on different versions. For example, the author found that the GNU Compiler Collection (GCC) \cite{GCC} 5.X C++ STL shipped with a broken version of the C++11 \cxxinline{<regex>} library. This bug was found late because testing on macOS's Xcode 8.3 and MSVC 2015 passed (the authors two main platforms). However, on a ``whim'' building on Linux was tested and the issue was found -- unit tests checked this functionality. This small issue opened up a question: How can the software be verified working on three major platforms while not having native access to each platform? The approach at the time was to change computers to access the different major operating systems. It became difficult to maintain what changes were made over time to have the project build properly. This meant that sharing the software development environment became difficult and near impossible to replicate at times. In previous works, the author had utilized VMWare vSphere \cite{VMWare:vSphere} technologies to create common developer ``environments'' through Virtual Machines that could be consistently used for development and testing. 

Given that vSphere is a proprietary and expensive software, the author researched other tools that provided virtualized environments. Oracle's VirtualBox \cite{Oracle:VirtualBox} provides virtual machine provisioning through open source tools. Building on the idea of ``cloning'' common configurations between development environments through VirtualBox, the author eventually found HashiCorp's Vagrant \cite{VagrantUp}. Vagrant provides a consistent declarative interface for defining a virtual machines configuration through Ruby scripts. Vagrant's parent company, Hashicorp, hosts ``boxes'' that are preconfigured virtual machines ranging from Ubuntu Linux to FreeBSD to macOS El Capitain \cite{Vagrant:Boxes}. These ``base'' boxes are then configured to match the environment requirements for a project. For example, \cref{lst:lua:ubuntu-vagrant-box} show cases a simple configuration that installs both GCC 5.X and Low-Level Virtual Machine (LLVM) Clang \cite{LLVM:Clang} 3.7 -- two fully C++11 compliant compiler tool-chains. These configurations are known as ``Vagrantfiles'' and are full Ruby programs, implying they can utilize Ruby's full ecosystem of software. The author used Vagrant and VirtualBox to create three environments for Microsoft Windows 10, macOS El Capitain, Ubuntu 14.04 Precise and Ubuntu 16.04 Xenial. These configurations allowed instantiating virtual machines quickly and consistently on any platform to build and run test configurations. With the three platforms easily accessible, it became necessary to improve the build infrastructure to be consistent across these platforms.

\begin{listing}[tp]
\begin{minted}[breaklines=true]{Ruby}
Vagrant.configure("2") do |config|
    # Utilize the ubuntu/trusty64 box to give a 14.04 environment
    config.vm.box = "ubuntu/trusty64"
    
    config.vm.provider "virtualbox" do |vb|
        vb.cpus = 2
        vb.memory = 2048
    end
    
    # Install/update prerequisite software:
    config.vm.provision "shell", privileged: true, inline: <<-EOF
        echo "Installing build prequisisites: git, compiler ppas"
        apt-get install -q -y git 
        # Compiler tool-chains
        apt-add-repository -y ppa:ubuntu-toolchain-r/test 
        apt-add-repository -y ppa:adrozdoff/llvm-backport 
        apt-get update -qq
    EOF
    
    config.vm.provision "shell", privileged: true, inline: <<-EOF
        echo "Installing build compiler toolchains"
        apt-get install -q -y clang-3.7 \
                              gcc-5 g++-5 \
                              --force-yes
    EOF
    
    # Update all existing packages last
    config.vm.provision "shell", privileged: true, inline: "apt-get dist-upgrade -y ; apt-get autoremove --purge -y"
end # end vagrant file 
\end{minted}
\caption{Vagrant file that describes a Ubuntu 14.04 box with modern GCC 5.X and LLVM Clang 3.7 compilers installed.}
\label{lst:lua:ubuntu-vagrant-box}
\end{listing} 

CMake \cite{Kitware:CMake} is a cross-platform meta-build system. A meta-build system provides a ``front-end'' language for defining a project's build and then generates a build program for other build systems to consume. CMake provides support for many different build systems, each is supported through a CMake ``generator''. The generators required to build on the Windows, macOS and Linux were ``Unix Makefiles'' for GNU \verb|make| \cite{GNU:Make} on Linux and macOS, ``Xcode'' for macOS's IDE Xcode \cite{Apple:Xcode}, and ``Visual Studio 14 2015 [Win64]'' for MSVC 2015 \cite{CMake:Generators}. On Unix environments, \verb|make| is generally available however and a newer build tool, \verb|ninja| \cite{NinjaBuild}, is preferred as builds are faster and provides the same familiar behaviours as \verb|make|. As stated, CMake provides a cross-platform meta-build system, however this meant writing cross-platform build scripts for the procsim project. In the original hc12sim project \cite{Brightwell2013}, CMake was utilized however it was poorly organized and added large coupling file dependencies. For example, changing a single file caused the entire build to trigger rather than just dependencies. At first, this was thought to be caused by CMake not properly structuring file dependencies, however it was soon found to be due to poor header isolation and deep, nested coupling. The author separated all headers to try and isolate concerns of what a header ``does'' and remove inter-dependencies as much as possible. Reorganization of the procsim library coupled with improved build tools and the addition of OBJECT library files \cite{CMake:add_library:ObjectLibraries} significantly reduced build time and allowed for less time spent compiling the procsim project. 

As previously discussed, compilers come with consequential differences in support for new and current standards. In order to try and utilize features appropriately it is often helpful to ``test'' compilers support of features. CMake provides this functionality through cmake-compiler-features \cite{CMake:compile-features} but CMake's built-in support lags heavily behind current C++ standards (including C++14 and 17 at the time of writing). Fortunately, the compatibility \cite{CMakeCompatibility} is a library used to enhance compiler and STL feature detection. The author worked with M\"uller to improve compatibility features and generation of header files that will include a ``shim'' on top of the current STL to add features where possible. ``Shims'' can only be added for STL features as syntax elements are not extensible in C++. The use of compatibility allows the procsim project to build more easily on the three major platforms. 

\subsection{Testing}

Testing a multi-platform compiled project is very difficult and relies on many tools to be successful. Through utilization of Vagrant and better build infrastructure within CMake scripts, the procsim project was able to be automatically tested on multiple platforms through continuous integration software. Continuous integration describes a process of building, testing and deploying software as rapidly as possible to reduce time-to-market for software projects \cite{Stolberg2009}. Idealistically, by utilizing continuous integration, developers receive near-instantaneous feedback on whether or not a particular change set breaks the product in unforeseen ways -- this heavily depends on the level of testing and environments available. For procsim, the author configured a small ``micro-PC'' with an Intel \textregistered{} i5-4590T and 4 GB of RAM to run a Jenkins \cite{Jenkins:Home} continuous integration server. 

Within Jenkins, Vagrant was used to create virtual machines that acted as ``slaves'' to the ``master'' Jenkins service utilizing Jenkins' distributed build infrastructure \cite{Jenkins:DistributedBuilds}. Each of these virtual machines was spawned to utilize a separate configuration to test the procsim project against. For example, one machine spawned a Ubuntu 14.04 machine with manually installed compiler tool-chains and a second machine spawned a macOS instance with Xcode 8. Each machine ran the exact same unit tests after configuration of the virtual machine and selection of a CMake generator. This was achieved utilizing a Jenkins Pipeline \cite{Jenkins:Pipeline} specified in a Jenkinsfile script \cite{Jenkins:Pipeline:Jenkinsfile}. Jenkins Pipelines allow for parallel execution of ``tasks,'' dependent and independent, for a continuous integration task graph. For the procsim project, due to its immaturity, the pipeline only included stages for building the software and running unit tests within the multiple operating system platforms required by \cref{req:personal}. While not strictly related to simulation \cref{req:simulations}, the addition of a continuous integration solution allowed the author to maintain a rapid pace of development and provide confidence that changes made worked across all platforms.  

Over the course of the procsim project, the build process became more and more complicated requiring improvements in automating the build process. When writing unit tests, the original hc12sim project utilized Boost.Test \cite{Boost1.53.0:Test} for creating and running unit tests. Unfortunately, Boost.Test required library distribution which made working on platforms without software distribution systems difficult (e.g. Windows or macOS). In order to remove the final thread of Boost binary dependence, the author replaced Boost.Test with Catch \cite{CatchLib}. Catch is a header-only C++ testing framework built on top of modern C++. The single-header configuration removed the final binary dependency. Catch provides a Behaviour-Driven Development (BDD) interface that allows developers to describe the behaviour of their system within their tests creating easily understandable and clearly organized tests \cite{Solis2011}. Catch improved the mechanisms used to test and provided an easier to maintain testing suite. Catch's test runner requires that all tests are defined through C-style macros and the executable must include Catch's main through \verb|main| the \cxxinline{CATCH_CONFIG_MAIN} macro \cite{CatchLib:Tutorial}. When defining many tests, it is often useful to organize them in meaningful ``suites'' of test executables. With any testing framework, when creating multiple executables it is advantageous to share object resources to reduce compiling time -- particularly in \cxxinline{template} or \cxxinline{constexpr} heavy software.

In \cref{sec:lua:sec:cross-platform-development}, CMake was discussed as the build tool for the procsim project. CMake utilizes OBJECT libraries to allow multiple ``targets'' to share compiled object files and statically link against the same objects as required. These OBJECT libraries are not the same as shared objects or DLLs and should not be treated as the same. An OBJECT library is a CMake abstraction on top of compiled compilation units that must be statically linked into some other object. These shared OBJECT libraries were very useful in unit test files as a common object used between each executable ``suite'' is the \verb|main| test runner. Manually specifying all of these suite instances to get individual suites and manually maintain a global ``test all'' suite was frustrating. The author developed a series of CMake macros \cite{CMake:macro} and functions \cite{CMake:function} to reduce the required commands to define tests and library files.

DESCRIBE HOW THESE FUNCTIONS WORK AND WHY THEY IMPROVE THE STATUS

\begin{listing}[hb]
\begin{minted}{CMake}
create_test(time     SOURCES time/ClockTest.cpp 
                             time/TimerTests.cpp
                     LIBS    procsim test-harness)
                     
create_test(encoding SOURCES encoding/CodeTest.cpp
                             encoding/OperandTest.cpp
                             encoding/PrimitivesTest.cpp
                             encoding/UtilityTest.cpp
                     LIBS    procsim test-harness)
                     
create_test(core     PROJECT)
\end{minted}
\caption{CMake script showing how two test suites, \mintinline{CMake}{time} and \mintinline{CMake}{encoding}, are defined as part of a project, \mintinline{CMake}{core}}
\label{lst:lua:cmake-test-declaration}
\end{listing}
 


\subsection{Configuration versus Simulation entities}
\lipsum[1]
% This directly translates into the organization of the procsim-ts project

\section{Utilizing runtime configurations through scripting}
\lipsum[1]

\subsection{Scripting language selection}
\lipsum[1]

% JavaScript via V8, Python via Boost.Python, SWIG and .. well anything, Lua + Luacppinterface/sol/sol2

\subsection{Lua integration}
\lipsum[1]

\section{Lua-based Configuration}

\lipsum[1]

\begin{listing}[hp!]
    \inputminted{lua}{./listings/x86_example.1.lua}
    \caption{Sample configuration showcasing a simple x86-like processor}
    \label{lst:lua:x86-example-1}
\end{listing}

\begin{listing*}[hp!]
    \inputminted[firstnumber=last]{lua}{./listings/x86_example.2.lua}
    \caption{(Continued) Sample configuration showcasing a simple x86-like processor}
    \label{lst:lua:x86-example-2}
\end{listing*}

\begin{listing*}[hp!]
    \inputminted[firstnumber=last]{lua}{./listings/x86_example.3.lua}
    \caption{(Continued) Sample configuration showcasing a simple x86-like processor}
    \label{lst:lua:x86-example-3}
\end{listing*}

\lipsum[2-4]

\section{Side-effect-based execution}
\lipsum[1]

\section{Technology challenges}
\lipsum[1]

\section{``Lessons learned''}
\lipsum[1]
